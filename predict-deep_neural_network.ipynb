{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import tensorflow as tf  \n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, median_absolute_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>meantempm</th>\n",
       "      <td>997.0</td>\n",
       "      <td>13.129388</td>\n",
       "      <td>10.971591</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxtempm</th>\n",
       "      <td>997.0</td>\n",
       "      <td>19.509529</td>\n",
       "      <td>11.577275</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>29.00</td>\n",
       "      <td>38.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mintempm</th>\n",
       "      <td>997.0</td>\n",
       "      <td>6.438315</td>\n",
       "      <td>10.957267</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.00</td>\n",
       "      <td>26.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meantempm_1</th>\n",
       "      <td>997.0</td>\n",
       "      <td>13.109328</td>\n",
       "      <td>10.984613</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meantempm_2</th>\n",
       "      <td>997.0</td>\n",
       "      <td>13.088265</td>\n",
       "      <td>11.001106</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meantempm_3</th>\n",
       "      <td>997.0</td>\n",
       "      <td>13.066199</td>\n",
       "      <td>11.017312</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meandewptm_1</th>\n",
       "      <td>997.0</td>\n",
       "      <td>6.440321</td>\n",
       "      <td>10.596265</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.00</td>\n",
       "      <td>24.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meandewptm_2</th>\n",
       "      <td>997.0</td>\n",
       "      <td>6.420261</td>\n",
       "      <td>10.606550</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.00</td>\n",
       "      <td>24.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meandewptm_3</th>\n",
       "      <td>997.0</td>\n",
       "      <td>6.393180</td>\n",
       "      <td>10.619083</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.00</td>\n",
       "      <td>24.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meanpressurem_1</th>\n",
       "      <td>997.0</td>\n",
       "      <td>1016.139418</td>\n",
       "      <td>7.582453</td>\n",
       "      <td>989.0</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>1021.00</td>\n",
       "      <td>1040.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meanpressurem_2</th>\n",
       "      <td>997.0</td>\n",
       "      <td>1016.142427</td>\n",
       "      <td>7.584185</td>\n",
       "      <td>989.0</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>1021.00</td>\n",
       "      <td>1040.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meanpressurem_3</th>\n",
       "      <td>997.0</td>\n",
       "      <td>1016.151454</td>\n",
       "      <td>7.586988</td>\n",
       "      <td>989.0</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>1021.00</td>\n",
       "      <td>1040.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxhumidity_1</th>\n",
       "      <td>997.0</td>\n",
       "      <td>88.107322</td>\n",
       "      <td>9.280627</td>\n",
       "      <td>47.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>93.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxhumidity_2</th>\n",
       "      <td>997.0</td>\n",
       "      <td>88.106319</td>\n",
       "      <td>9.280152</td>\n",
       "      <td>47.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>93.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxhumidity_3</th>\n",
       "      <td>997.0</td>\n",
       "      <td>88.093280</td>\n",
       "      <td>9.276775</td>\n",
       "      <td>47.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>93.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minhumidity_1</th>\n",
       "      <td>997.0</td>\n",
       "      <td>46.025075</td>\n",
       "      <td>16.108517</td>\n",
       "      <td>9.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>56.00</td>\n",
       "      <td>92.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minhumidity_2</th>\n",
       "      <td>997.0</td>\n",
       "      <td>46.021063</td>\n",
       "      <td>16.105530</td>\n",
       "      <td>9.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>56.00</td>\n",
       "      <td>92.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minhumidity_3</th>\n",
       "      <td>997.0</td>\n",
       "      <td>45.984955</td>\n",
       "      <td>16.047081</td>\n",
       "      <td>9.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>56.00</td>\n",
       "      <td>92.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxtempm_1</th>\n",
       "      <td>997.0</td>\n",
       "      <td>19.489468</td>\n",
       "      <td>11.588542</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>29.00</td>\n",
       "      <td>38.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxtempm_2</th>\n",
       "      <td>997.0</td>\n",
       "      <td>19.471414</td>\n",
       "      <td>11.603318</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>29.00</td>\n",
       "      <td>38.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxtempm_3</th>\n",
       "      <td>997.0</td>\n",
       "      <td>19.455366</td>\n",
       "      <td>11.616412</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>29.00</td>\n",
       "      <td>38.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mintempm_1</th>\n",
       "      <td>997.0</td>\n",
       "      <td>6.417252</td>\n",
       "      <td>10.974433</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.00</td>\n",
       "      <td>26.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mintempm_2</th>\n",
       "      <td>997.0</td>\n",
       "      <td>6.394183</td>\n",
       "      <td>10.988954</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.00</td>\n",
       "      <td>26.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mintempm_3</th>\n",
       "      <td>997.0</td>\n",
       "      <td>6.367101</td>\n",
       "      <td>11.003451</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.00</td>\n",
       "      <td>26.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxdewptm_1</th>\n",
       "      <td>997.0</td>\n",
       "      <td>9.378134</td>\n",
       "      <td>10.160778</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>18.00</td>\n",
       "      <td>26.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxdewptm_2</th>\n",
       "      <td>997.0</td>\n",
       "      <td>9.359077</td>\n",
       "      <td>10.171790</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>18.00</td>\n",
       "      <td>26.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxdewptm_3</th>\n",
       "      <td>997.0</td>\n",
       "      <td>9.336008</td>\n",
       "      <td>10.180521</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>18.00</td>\n",
       "      <td>26.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mindewptm_1</th>\n",
       "      <td>997.0</td>\n",
       "      <td>3.251755</td>\n",
       "      <td>11.225411</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.00</td>\n",
       "      <td>22.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mindewptm_2</th>\n",
       "      <td>997.0</td>\n",
       "      <td>3.229689</td>\n",
       "      <td>11.235718</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.00</td>\n",
       "      <td>22.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mindewptm_3</th>\n",
       "      <td>997.0</td>\n",
       "      <td>3.198596</td>\n",
       "      <td>11.251536</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.00</td>\n",
       "      <td>22.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxpressurem_1</th>\n",
       "      <td>997.0</td>\n",
       "      <td>1019.913741</td>\n",
       "      <td>7.755590</td>\n",
       "      <td>993.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1024.00</td>\n",
       "      <td>1055.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxpressurem_2</th>\n",
       "      <td>997.0</td>\n",
       "      <td>1019.917753</td>\n",
       "      <td>7.757705</td>\n",
       "      <td>993.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1024.00</td>\n",
       "      <td>1055.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxpressurem_3</th>\n",
       "      <td>997.0</td>\n",
       "      <td>1019.927783</td>\n",
       "      <td>7.757805</td>\n",
       "      <td>993.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1024.00</td>\n",
       "      <td>1055.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minpressurem_1</th>\n",
       "      <td>997.0</td>\n",
       "      <td>1012.317954</td>\n",
       "      <td>7.885743</td>\n",
       "      <td>956.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>1017.00</td>\n",
       "      <td>1035.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minpressurem_2</th>\n",
       "      <td>997.0</td>\n",
       "      <td>1012.319960</td>\n",
       "      <td>7.886681</td>\n",
       "      <td>956.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>1017.00</td>\n",
       "      <td>1035.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minpressurem_3</th>\n",
       "      <td>997.0</td>\n",
       "      <td>1012.326981</td>\n",
       "      <td>7.889511</td>\n",
       "      <td>956.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>1017.00</td>\n",
       "      <td>1035.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precipm_1</th>\n",
       "      <td>997.0</td>\n",
       "      <td>2.593180</td>\n",
       "      <td>8.428058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>95.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precipm_2</th>\n",
       "      <td>997.0</td>\n",
       "      <td>2.593180</td>\n",
       "      <td>8.428058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>95.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precipm_3</th>\n",
       "      <td>997.0</td>\n",
       "      <td>2.573049</td>\n",
       "      <td>8.410223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>95.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 count         mean        std    min     25%     50%  \\\n",
       "meantempm        997.0    13.129388  10.971591  -17.0     5.0    15.0   \n",
       "maxtempm         997.0    19.509529  11.577275  -12.0    11.0    22.0   \n",
       "mintempm         997.0     6.438315  10.957267  -27.0    -2.0     7.0   \n",
       "meantempm_1      997.0    13.109328  10.984613  -17.0     5.0    15.0   \n",
       "meantempm_2      997.0    13.088265  11.001106  -17.0     5.0    14.0   \n",
       "meantempm_3      997.0    13.066199  11.017312  -17.0     5.0    14.0   \n",
       "meandewptm_1     997.0     6.440321  10.596265  -22.0    -2.0     7.0   \n",
       "meandewptm_2     997.0     6.420261  10.606550  -22.0    -2.0     7.0   \n",
       "meandewptm_3     997.0     6.393180  10.619083  -22.0    -2.0     7.0   \n",
       "meanpressurem_1  997.0  1016.139418   7.582453  989.0  1011.0  1016.0   \n",
       "meanpressurem_2  997.0  1016.142427   7.584185  989.0  1011.0  1016.0   \n",
       "meanpressurem_3  997.0  1016.151454   7.586988  989.0  1011.0  1016.0   \n",
       "maxhumidity_1    997.0    88.107322   9.280627   47.0    83.0    90.0   \n",
       "maxhumidity_2    997.0    88.106319   9.280152   47.0    83.0    90.0   \n",
       "maxhumidity_3    997.0    88.093280   9.276775   47.0    83.0    90.0   \n",
       "minhumidity_1    997.0    46.025075  16.108517    9.0    35.0    45.0   \n",
       "minhumidity_2    997.0    46.021063  16.105530    9.0    35.0    45.0   \n",
       "minhumidity_3    997.0    45.984955  16.047081    9.0    35.0    45.0   \n",
       "maxtempm_1       997.0    19.489468  11.588542  -12.0    11.0    22.0   \n",
       "maxtempm_2       997.0    19.471414  11.603318  -12.0    11.0    22.0   \n",
       "maxtempm_3       997.0    19.455366  11.616412  -12.0    11.0    22.0   \n",
       "mintempm_1       997.0     6.417252  10.974433  -27.0    -2.0     7.0   \n",
       "mintempm_2       997.0     6.394183  10.988954  -27.0    -2.0     7.0   \n",
       "mintempm_3       997.0     6.367101  11.003451  -27.0    -2.0     7.0   \n",
       "maxdewptm_1      997.0     9.378134  10.160778  -18.0     1.0    11.0   \n",
       "maxdewptm_2      997.0     9.359077  10.171790  -18.0     1.0    11.0   \n",
       "maxdewptm_3      997.0     9.336008  10.180521  -18.0     1.0    11.0   \n",
       "mindewptm_1      997.0     3.251755  11.225411  -28.0    -6.0     4.0   \n",
       "mindewptm_2      997.0     3.229689  11.235718  -28.0    -6.0     4.0   \n",
       "mindewptm_3      997.0     3.198596  11.251536  -28.0    -6.0     4.0   \n",
       "maxpressurem_1   997.0  1019.913741   7.755590  993.0  1015.0  1019.0   \n",
       "maxpressurem_2   997.0  1019.917753   7.757705  993.0  1015.0  1019.0   \n",
       "maxpressurem_3   997.0  1019.927783   7.757805  993.0  1015.0  1019.0   \n",
       "minpressurem_1   997.0  1012.317954   7.885743  956.0  1008.0  1012.0   \n",
       "minpressurem_2   997.0  1012.319960   7.886681  956.0  1008.0  1012.0   \n",
       "minpressurem_3   997.0  1012.326981   7.889511  956.0  1008.0  1012.0   \n",
       "precipm_1        997.0     2.593180   8.428058    0.0     0.0     0.0   \n",
       "precipm_2        997.0     2.593180   8.428058    0.0     0.0     0.0   \n",
       "precipm_3        997.0     2.573049   8.410223    0.0     0.0     0.0   \n",
       "\n",
       "                     75%      max  \n",
       "meantempm          22.00    32.00  \n",
       "maxtempm           29.00    38.00  \n",
       "mintempm           16.00    26.00  \n",
       "meantempm_1        22.00    32.00  \n",
       "meantempm_2        22.00    32.00  \n",
       "meantempm_3        22.00    32.00  \n",
       "meandewptm_1       16.00    24.00  \n",
       "meandewptm_2       16.00    24.00  \n",
       "meandewptm_3       16.00    24.00  \n",
       "meanpressurem_1  1021.00  1040.00  \n",
       "meanpressurem_2  1021.00  1040.00  \n",
       "meanpressurem_3  1021.00  1040.00  \n",
       "maxhumidity_1      93.00   100.00  \n",
       "maxhumidity_2      93.00   100.00  \n",
       "maxhumidity_3      93.00   100.00  \n",
       "minhumidity_1      56.00    92.00  \n",
       "minhumidity_2      56.00    92.00  \n",
       "minhumidity_3      56.00    92.00  \n",
       "maxtempm_1         29.00    38.00  \n",
       "maxtempm_2         29.00    38.00  \n",
       "maxtempm_3         29.00    38.00  \n",
       "mintempm_1         16.00    26.00  \n",
       "mintempm_2         16.00    26.00  \n",
       "mintempm_3         16.00    26.00  \n",
       "maxdewptm_1        18.00    26.00  \n",
       "maxdewptm_2        18.00    26.00  \n",
       "maxdewptm_3        18.00    26.00  \n",
       "mindewptm_1        13.00    22.00  \n",
       "mindewptm_2        13.00    22.00  \n",
       "mindewptm_3        13.00    22.00  \n",
       "maxpressurem_1   1024.00  1055.00  \n",
       "maxpressurem_2   1024.00  1055.00  \n",
       "maxpressurem_3   1024.00  1055.00  \n",
       "minpressurem_1   1017.00  1035.00  \n",
       "minpressurem_2   1017.00  1035.00  \n",
       "minpressurem_3   1017.00  1035.00  \n",
       "precipm_1           0.25    95.76  \n",
       "precipm_2           0.25    95.76  \n",
       "precipm_3           0.25    95.76  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the csv data into a pandas data frame and set the date as the index\n",
    "df = pd.read_csv('end-part2_df.csv').set_index('date')\n",
    "\n",
    "# execute the describe() function and transpose the output so that it doesn't overflow the width of the screen\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meantempm</th>\n",
       "      <th>maxtempm</th>\n",
       "      <th>mintempm</th>\n",
       "      <th>meantempm_1</th>\n",
       "      <th>meantempm_2</th>\n",
       "      <th>meantempm_3</th>\n",
       "      <th>meandewptm_1</th>\n",
       "      <th>meandewptm_2</th>\n",
       "      <th>meandewptm_3</th>\n",
       "      <th>meanpressurem_1</th>\n",
       "      <th>...</th>\n",
       "      <th>mindewptm_3</th>\n",
       "      <th>maxpressurem_1</th>\n",
       "      <th>maxpressurem_2</th>\n",
       "      <th>maxpressurem_3</th>\n",
       "      <th>minpressurem_1</th>\n",
       "      <th>minpressurem_2</th>\n",
       "      <th>minpressurem_3</th>\n",
       "      <th>precipm_1</th>\n",
       "      <th>precipm_2</th>\n",
       "      <th>precipm_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>997.000000</td>\n",
       "      <td>997.000000</td>\n",
       "      <td>997.000000</td>\n",
       "      <td>997.000000</td>\n",
       "      <td>997.000000</td>\n",
       "      <td>997.000000</td>\n",
       "      <td>997.000000</td>\n",
       "      <td>997.000000</td>\n",
       "      <td>997.000000</td>\n",
       "      <td>997.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>997.000000</td>\n",
       "      <td>997.000000</td>\n",
       "      <td>997.000000</td>\n",
       "      <td>997.000000</td>\n",
       "      <td>997.000000</td>\n",
       "      <td>997.000000</td>\n",
       "      <td>997.000000</td>\n",
       "      <td>997.000000</td>\n",
       "      <td>997.000000</td>\n",
       "      <td>997.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13.129388</td>\n",
       "      <td>19.509529</td>\n",
       "      <td>6.438315</td>\n",
       "      <td>13.109328</td>\n",
       "      <td>13.088265</td>\n",
       "      <td>13.066199</td>\n",
       "      <td>6.440321</td>\n",
       "      <td>6.420261</td>\n",
       "      <td>6.393180</td>\n",
       "      <td>1016.139418</td>\n",
       "      <td>...</td>\n",
       "      <td>3.198596</td>\n",
       "      <td>1019.913741</td>\n",
       "      <td>1019.917753</td>\n",
       "      <td>1019.927783</td>\n",
       "      <td>1012.317954</td>\n",
       "      <td>1012.319960</td>\n",
       "      <td>1012.326981</td>\n",
       "      <td>2.593180</td>\n",
       "      <td>2.593180</td>\n",
       "      <td>2.573049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.971591</td>\n",
       "      <td>11.577275</td>\n",
       "      <td>10.957267</td>\n",
       "      <td>10.984613</td>\n",
       "      <td>11.001106</td>\n",
       "      <td>11.017312</td>\n",
       "      <td>10.596265</td>\n",
       "      <td>10.606550</td>\n",
       "      <td>10.619083</td>\n",
       "      <td>7.582453</td>\n",
       "      <td>...</td>\n",
       "      <td>11.251536</td>\n",
       "      <td>7.755590</td>\n",
       "      <td>7.757705</td>\n",
       "      <td>7.757805</td>\n",
       "      <td>7.885743</td>\n",
       "      <td>7.886681</td>\n",
       "      <td>7.889511</td>\n",
       "      <td>8.428058</td>\n",
       "      <td>8.428058</td>\n",
       "      <td>8.410223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-17.000000</td>\n",
       "      <td>-12.000000</td>\n",
       "      <td>-27.000000</td>\n",
       "      <td>-17.000000</td>\n",
       "      <td>-17.000000</td>\n",
       "      <td>-17.000000</td>\n",
       "      <td>-22.000000</td>\n",
       "      <td>-22.000000</td>\n",
       "      <td>-22.000000</td>\n",
       "      <td>989.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-28.000000</td>\n",
       "      <td>993.000000</td>\n",
       "      <td>993.000000</td>\n",
       "      <td>993.000000</td>\n",
       "      <td>956.000000</td>\n",
       "      <td>956.000000</td>\n",
       "      <td>956.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>1011.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>1015.000000</td>\n",
       "      <td>1015.000000</td>\n",
       "      <td>1015.000000</td>\n",
       "      <td>1008.000000</td>\n",
       "      <td>1008.000000</td>\n",
       "      <td>1008.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1016.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1019.000000</td>\n",
       "      <td>1019.000000</td>\n",
       "      <td>1019.000000</td>\n",
       "      <td>1012.000000</td>\n",
       "      <td>1012.000000</td>\n",
       "      <td>1012.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1021.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1024.000000</td>\n",
       "      <td>1024.000000</td>\n",
       "      <td>1024.000000</td>\n",
       "      <td>1017.000000</td>\n",
       "      <td>1017.000000</td>\n",
       "      <td>1017.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1040.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1055.000000</td>\n",
       "      <td>1055.000000</td>\n",
       "      <td>1055.000000</td>\n",
       "      <td>1035.000000</td>\n",
       "      <td>1035.000000</td>\n",
       "      <td>1035.000000</td>\n",
       "      <td>95.760000</td>\n",
       "      <td>95.760000</td>\n",
       "      <td>95.760000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        meantempm    maxtempm    mintempm  meantempm_1  meantempm_2  \\\n",
       "count  997.000000  997.000000  997.000000   997.000000   997.000000   \n",
       "mean    13.129388   19.509529    6.438315    13.109328    13.088265   \n",
       "std     10.971591   11.577275   10.957267    10.984613    11.001106   \n",
       "min    -17.000000  -12.000000  -27.000000   -17.000000   -17.000000   \n",
       "25%      5.000000   11.000000   -2.000000     5.000000     5.000000   \n",
       "50%     15.000000   22.000000    7.000000    15.000000    14.000000   \n",
       "75%     22.000000   29.000000   16.000000    22.000000    22.000000   \n",
       "max     32.000000   38.000000   26.000000    32.000000    32.000000   \n",
       "\n",
       "       meantempm_3  meandewptm_1  meandewptm_2  meandewptm_3  meanpressurem_1  \\\n",
       "count   997.000000    997.000000    997.000000    997.000000       997.000000   \n",
       "mean     13.066199      6.440321      6.420261      6.393180      1016.139418   \n",
       "std      11.017312     10.596265     10.606550     10.619083         7.582453   \n",
       "min     -17.000000    -22.000000    -22.000000    -22.000000       989.000000   \n",
       "25%       5.000000     -2.000000     -2.000000     -2.000000      1011.000000   \n",
       "50%      14.000000      7.000000      7.000000      7.000000      1016.000000   \n",
       "75%      22.000000     16.000000     16.000000     16.000000      1021.000000   \n",
       "max      32.000000     24.000000     24.000000     24.000000      1040.000000   \n",
       "\n",
       "          ...      mindewptm_3  maxpressurem_1  maxpressurem_2  \\\n",
       "count     ...       997.000000      997.000000      997.000000   \n",
       "mean      ...         3.198596     1019.913741     1019.917753   \n",
       "std       ...        11.251536        7.755590        7.757705   \n",
       "min       ...       -28.000000      993.000000      993.000000   \n",
       "25%       ...        -6.000000     1015.000000     1015.000000   \n",
       "50%       ...         4.000000     1019.000000     1019.000000   \n",
       "75%       ...        13.000000     1024.000000     1024.000000   \n",
       "max       ...        22.000000     1055.000000     1055.000000   \n",
       "\n",
       "       maxpressurem_3  minpressurem_1  minpressurem_2  minpressurem_3  \\\n",
       "count      997.000000      997.000000      997.000000      997.000000   \n",
       "mean      1019.927783     1012.317954     1012.319960     1012.326981   \n",
       "std          7.757805        7.885743        7.886681        7.889511   \n",
       "min        993.000000      956.000000      956.000000      956.000000   \n",
       "25%       1015.000000     1008.000000     1008.000000     1008.000000   \n",
       "50%       1019.000000     1012.000000     1012.000000     1012.000000   \n",
       "75%       1024.000000     1017.000000     1017.000000     1017.000000   \n",
       "max       1055.000000     1035.000000     1035.000000     1035.000000   \n",
       "\n",
       "        precipm_1   precipm_2   precipm_3  \n",
       "count  997.000000  997.000000  997.000000  \n",
       "mean     2.593180    2.593180    2.573049  \n",
       "std      8.428058    8.428058    8.410223  \n",
       "min      0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000000  \n",
       "50%      0.000000    0.000000    0.000000  \n",
       "75%      0.250000    0.250000    0.250000  \n",
       "max     95.760000   95.760000   95.760000  \n",
       "\n",
       "[8 rows x 39 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>meantempm</th>\n",
       "      <td>997.0</td>\n",
       "      <td>13.129388</td>\n",
       "      <td>10.971591</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxtempm</th>\n",
       "      <td>997.0</td>\n",
       "      <td>19.509529</td>\n",
       "      <td>11.577275</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>29.00</td>\n",
       "      <td>38.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mintempm</th>\n",
       "      <td>997.0</td>\n",
       "      <td>6.438315</td>\n",
       "      <td>10.957267</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.00</td>\n",
       "      <td>26.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meantempm_1</th>\n",
       "      <td>997.0</td>\n",
       "      <td>13.109328</td>\n",
       "      <td>10.984613</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meantempm_2</th>\n",
       "      <td>997.0</td>\n",
       "      <td>13.088265</td>\n",
       "      <td>11.001106</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meantempm_3</th>\n",
       "      <td>997.0</td>\n",
       "      <td>13.066199</td>\n",
       "      <td>11.017312</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meandewptm_1</th>\n",
       "      <td>997.0</td>\n",
       "      <td>6.440321</td>\n",
       "      <td>10.596265</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.00</td>\n",
       "      <td>24.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meandewptm_2</th>\n",
       "      <td>997.0</td>\n",
       "      <td>6.420261</td>\n",
       "      <td>10.606550</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.00</td>\n",
       "      <td>24.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meandewptm_3</th>\n",
       "      <td>997.0</td>\n",
       "      <td>6.393180</td>\n",
       "      <td>10.619083</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.00</td>\n",
       "      <td>24.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meanpressurem_1</th>\n",
       "      <td>997.0</td>\n",
       "      <td>1016.139418</td>\n",
       "      <td>7.582453</td>\n",
       "      <td>989.0</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>1021.00</td>\n",
       "      <td>1040.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meanpressurem_2</th>\n",
       "      <td>997.0</td>\n",
       "      <td>1016.142427</td>\n",
       "      <td>7.584185</td>\n",
       "      <td>989.0</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>1021.00</td>\n",
       "      <td>1040.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meanpressurem_3</th>\n",
       "      <td>997.0</td>\n",
       "      <td>1016.151454</td>\n",
       "      <td>7.586988</td>\n",
       "      <td>989.0</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>1021.00</td>\n",
       "      <td>1040.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxhumidity_1</th>\n",
       "      <td>997.0</td>\n",
       "      <td>88.107322</td>\n",
       "      <td>9.280627</td>\n",
       "      <td>47.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>93.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxhumidity_2</th>\n",
       "      <td>997.0</td>\n",
       "      <td>88.106319</td>\n",
       "      <td>9.280152</td>\n",
       "      <td>47.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>93.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxhumidity_3</th>\n",
       "      <td>997.0</td>\n",
       "      <td>88.093280</td>\n",
       "      <td>9.276775</td>\n",
       "      <td>47.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>93.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minhumidity_1</th>\n",
       "      <td>997.0</td>\n",
       "      <td>46.025075</td>\n",
       "      <td>16.108517</td>\n",
       "      <td>9.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>56.00</td>\n",
       "      <td>92.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minhumidity_2</th>\n",
       "      <td>997.0</td>\n",
       "      <td>46.021063</td>\n",
       "      <td>16.105530</td>\n",
       "      <td>9.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>56.00</td>\n",
       "      <td>92.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minhumidity_3</th>\n",
       "      <td>997.0</td>\n",
       "      <td>45.984955</td>\n",
       "      <td>16.047081</td>\n",
       "      <td>9.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>56.00</td>\n",
       "      <td>92.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxtempm_1</th>\n",
       "      <td>997.0</td>\n",
       "      <td>19.489468</td>\n",
       "      <td>11.588542</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>29.00</td>\n",
       "      <td>38.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxtempm_2</th>\n",
       "      <td>997.0</td>\n",
       "      <td>19.471414</td>\n",
       "      <td>11.603318</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>29.00</td>\n",
       "      <td>38.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxtempm_3</th>\n",
       "      <td>997.0</td>\n",
       "      <td>19.455366</td>\n",
       "      <td>11.616412</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>29.00</td>\n",
       "      <td>38.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mintempm_1</th>\n",
       "      <td>997.0</td>\n",
       "      <td>6.417252</td>\n",
       "      <td>10.974433</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.00</td>\n",
       "      <td>26.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mintempm_2</th>\n",
       "      <td>997.0</td>\n",
       "      <td>6.394183</td>\n",
       "      <td>10.988954</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.00</td>\n",
       "      <td>26.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mintempm_3</th>\n",
       "      <td>997.0</td>\n",
       "      <td>6.367101</td>\n",
       "      <td>11.003451</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.00</td>\n",
       "      <td>26.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxdewptm_1</th>\n",
       "      <td>997.0</td>\n",
       "      <td>9.378134</td>\n",
       "      <td>10.160778</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>18.00</td>\n",
       "      <td>26.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxdewptm_2</th>\n",
       "      <td>997.0</td>\n",
       "      <td>9.359077</td>\n",
       "      <td>10.171790</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>18.00</td>\n",
       "      <td>26.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxdewptm_3</th>\n",
       "      <td>997.0</td>\n",
       "      <td>9.336008</td>\n",
       "      <td>10.180521</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>18.00</td>\n",
       "      <td>26.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mindewptm_1</th>\n",
       "      <td>997.0</td>\n",
       "      <td>3.251755</td>\n",
       "      <td>11.225411</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.00</td>\n",
       "      <td>22.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mindewptm_2</th>\n",
       "      <td>997.0</td>\n",
       "      <td>3.229689</td>\n",
       "      <td>11.235718</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.00</td>\n",
       "      <td>22.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mindewptm_3</th>\n",
       "      <td>997.0</td>\n",
       "      <td>3.198596</td>\n",
       "      <td>11.251536</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.00</td>\n",
       "      <td>22.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxpressurem_1</th>\n",
       "      <td>997.0</td>\n",
       "      <td>1019.913741</td>\n",
       "      <td>7.755590</td>\n",
       "      <td>993.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1024.00</td>\n",
       "      <td>1055.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxpressurem_2</th>\n",
       "      <td>997.0</td>\n",
       "      <td>1019.917753</td>\n",
       "      <td>7.757705</td>\n",
       "      <td>993.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1024.00</td>\n",
       "      <td>1055.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxpressurem_3</th>\n",
       "      <td>997.0</td>\n",
       "      <td>1019.927783</td>\n",
       "      <td>7.757805</td>\n",
       "      <td>993.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1024.00</td>\n",
       "      <td>1055.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minpressurem_1</th>\n",
       "      <td>997.0</td>\n",
       "      <td>1012.317954</td>\n",
       "      <td>7.885743</td>\n",
       "      <td>956.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>1017.00</td>\n",
       "      <td>1035.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minpressurem_2</th>\n",
       "      <td>997.0</td>\n",
       "      <td>1012.319960</td>\n",
       "      <td>7.886681</td>\n",
       "      <td>956.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>1017.00</td>\n",
       "      <td>1035.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minpressurem_3</th>\n",
       "      <td>997.0</td>\n",
       "      <td>1012.326981</td>\n",
       "      <td>7.889511</td>\n",
       "      <td>956.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>1017.00</td>\n",
       "      <td>1035.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precipm_1</th>\n",
       "      <td>997.0</td>\n",
       "      <td>2.593180</td>\n",
       "      <td>8.428058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>95.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precipm_2</th>\n",
       "      <td>997.0</td>\n",
       "      <td>2.593180</td>\n",
       "      <td>8.428058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>95.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precipm_3</th>\n",
       "      <td>997.0</td>\n",
       "      <td>2.573049</td>\n",
       "      <td>8.410223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>95.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 count         mean        std    min     25%     50%  \\\n",
       "meantempm        997.0    13.129388  10.971591  -17.0     5.0    15.0   \n",
       "maxtempm         997.0    19.509529  11.577275  -12.0    11.0    22.0   \n",
       "mintempm         997.0     6.438315  10.957267  -27.0    -2.0     7.0   \n",
       "meantempm_1      997.0    13.109328  10.984613  -17.0     5.0    15.0   \n",
       "meantempm_2      997.0    13.088265  11.001106  -17.0     5.0    14.0   \n",
       "meantempm_3      997.0    13.066199  11.017312  -17.0     5.0    14.0   \n",
       "meandewptm_1     997.0     6.440321  10.596265  -22.0    -2.0     7.0   \n",
       "meandewptm_2     997.0     6.420261  10.606550  -22.0    -2.0     7.0   \n",
       "meandewptm_3     997.0     6.393180  10.619083  -22.0    -2.0     7.0   \n",
       "meanpressurem_1  997.0  1016.139418   7.582453  989.0  1011.0  1016.0   \n",
       "meanpressurem_2  997.0  1016.142427   7.584185  989.0  1011.0  1016.0   \n",
       "meanpressurem_3  997.0  1016.151454   7.586988  989.0  1011.0  1016.0   \n",
       "maxhumidity_1    997.0    88.107322   9.280627   47.0    83.0    90.0   \n",
       "maxhumidity_2    997.0    88.106319   9.280152   47.0    83.0    90.0   \n",
       "maxhumidity_3    997.0    88.093280   9.276775   47.0    83.0    90.0   \n",
       "minhumidity_1    997.0    46.025075  16.108517    9.0    35.0    45.0   \n",
       "minhumidity_2    997.0    46.021063  16.105530    9.0    35.0    45.0   \n",
       "minhumidity_3    997.0    45.984955  16.047081    9.0    35.0    45.0   \n",
       "maxtempm_1       997.0    19.489468  11.588542  -12.0    11.0    22.0   \n",
       "maxtempm_2       997.0    19.471414  11.603318  -12.0    11.0    22.0   \n",
       "maxtempm_3       997.0    19.455366  11.616412  -12.0    11.0    22.0   \n",
       "mintempm_1       997.0     6.417252  10.974433  -27.0    -2.0     7.0   \n",
       "mintempm_2       997.0     6.394183  10.988954  -27.0    -2.0     7.0   \n",
       "mintempm_3       997.0     6.367101  11.003451  -27.0    -2.0     7.0   \n",
       "maxdewptm_1      997.0     9.378134  10.160778  -18.0     1.0    11.0   \n",
       "maxdewptm_2      997.0     9.359077  10.171790  -18.0     1.0    11.0   \n",
       "maxdewptm_3      997.0     9.336008  10.180521  -18.0     1.0    11.0   \n",
       "mindewptm_1      997.0     3.251755  11.225411  -28.0    -6.0     4.0   \n",
       "mindewptm_2      997.0     3.229689  11.235718  -28.0    -6.0     4.0   \n",
       "mindewptm_3      997.0     3.198596  11.251536  -28.0    -6.0     4.0   \n",
       "maxpressurem_1   997.0  1019.913741   7.755590  993.0  1015.0  1019.0   \n",
       "maxpressurem_2   997.0  1019.917753   7.757705  993.0  1015.0  1019.0   \n",
       "maxpressurem_3   997.0  1019.927783   7.757805  993.0  1015.0  1019.0   \n",
       "minpressurem_1   997.0  1012.317954   7.885743  956.0  1008.0  1012.0   \n",
       "minpressurem_2   997.0  1012.319960   7.886681  956.0  1008.0  1012.0   \n",
       "minpressurem_3   997.0  1012.326981   7.889511  956.0  1008.0  1012.0   \n",
       "precipm_1        997.0     2.593180   8.428058    0.0     0.0     0.0   \n",
       "precipm_2        997.0     2.593180   8.428058    0.0     0.0     0.0   \n",
       "precipm_3        997.0     2.573049   8.410223    0.0     0.0     0.0   \n",
       "\n",
       "                     75%      max  \n",
       "meantempm          22.00    32.00  \n",
       "maxtempm           29.00    38.00  \n",
       "mintempm           16.00    26.00  \n",
       "meantempm_1        22.00    32.00  \n",
       "meantempm_2        22.00    32.00  \n",
       "meantempm_3        22.00    32.00  \n",
       "meandewptm_1       16.00    24.00  \n",
       "meandewptm_2       16.00    24.00  \n",
       "meandewptm_3       16.00    24.00  \n",
       "meanpressurem_1  1021.00  1040.00  \n",
       "meanpressurem_2  1021.00  1040.00  \n",
       "meanpressurem_3  1021.00  1040.00  \n",
       "maxhumidity_1      93.00   100.00  \n",
       "maxhumidity_2      93.00   100.00  \n",
       "maxhumidity_3      93.00   100.00  \n",
       "minhumidity_1      56.00    92.00  \n",
       "minhumidity_2      56.00    92.00  \n",
       "minhumidity_3      56.00    92.00  \n",
       "maxtempm_1         29.00    38.00  \n",
       "maxtempm_2         29.00    38.00  \n",
       "maxtempm_3         29.00    38.00  \n",
       "mintempm_1         16.00    26.00  \n",
       "mintempm_2         16.00    26.00  \n",
       "mintempm_3         16.00    26.00  \n",
       "maxdewptm_1        18.00    26.00  \n",
       "maxdewptm_2        18.00    26.00  \n",
       "maxdewptm_3        18.00    26.00  \n",
       "mindewptm_1        13.00    22.00  \n",
       "mindewptm_2        13.00    22.00  \n",
       "mindewptm_3        13.00    22.00  \n",
       "maxpressurem_1   1024.00  1055.00  \n",
       "maxpressurem_2   1024.00  1055.00  \n",
       "maxpressurem_3   1024.00  1055.00  \n",
       "minpressurem_1   1017.00  1035.00  \n",
       "minpressurem_2   1017.00  1035.00  \n",
       "minpressurem_3   1017.00  1035.00  \n",
       "precipm_1           0.25    95.76  \n",
       "precipm_2           0.25    95.76  \n",
       "precipm_3           0.25    95.76  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 997 entries, 2015-01-04 to 2017-09-27\n",
      "Data columns (total 39 columns):\n",
      "meantempm          997 non-null int64\n",
      "maxtempm           997 non-null int64\n",
      "mintempm           997 non-null int64\n",
      "meantempm_1        997 non-null float64\n",
      "meantempm_2        997 non-null float64\n",
      "meantempm_3        997 non-null float64\n",
      "meandewptm_1       997 non-null float64\n",
      "meandewptm_2       997 non-null float64\n",
      "meandewptm_3       997 non-null float64\n",
      "meanpressurem_1    997 non-null float64\n",
      "meanpressurem_2    997 non-null float64\n",
      "meanpressurem_3    997 non-null float64\n",
      "maxhumidity_1      997 non-null float64\n",
      "maxhumidity_2      997 non-null float64\n",
      "maxhumidity_3      997 non-null float64\n",
      "minhumidity_1      997 non-null float64\n",
      "minhumidity_2      997 non-null float64\n",
      "minhumidity_3      997 non-null float64\n",
      "maxtempm_1         997 non-null float64\n",
      "maxtempm_2         997 non-null float64\n",
      "maxtempm_3         997 non-null float64\n",
      "mintempm_1         997 non-null float64\n",
      "mintempm_2         997 non-null float64\n",
      "mintempm_3         997 non-null float64\n",
      "maxdewptm_1        997 non-null float64\n",
      "maxdewptm_2        997 non-null float64\n",
      "maxdewptm_3        997 non-null float64\n",
      "mindewptm_1        997 non-null float64\n",
      "mindewptm_2        997 non-null float64\n",
      "mindewptm_3        997 non-null float64\n",
      "maxpressurem_1     997 non-null float64\n",
      "maxpressurem_2     997 non-null float64\n",
      "maxpressurem_3     997 non-null float64\n",
      "minpressurem_1     997 non-null float64\n",
      "minpressurem_2     997 non-null float64\n",
      "minpressurem_3     997 non-null float64\n",
      "precipm_1          997 non-null float64\n",
      "precipm_2          997 non-null float64\n",
      "precipm_3          997 non-null float64\n",
      "dtypes: float64(36), int64(3)\n",
      "memory usage: 311.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# execute the info() function\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First drop the maxtempm and mintempm from the dataframe\n",
    "df = df.drop(['mintempm', 'maxtempm'], axis=1)\n",
    "\n",
    "# X will be a pandas dataframe of all columns except meantempm\n",
    "X = df[[col for col in df.columns if col != 'meantempm']]\n",
    "\n",
    "# y will be a pandas series of the meantempm\n",
    "y = df['meantempm']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meantempm_1</th>\n",
       "      <th>meantempm_2</th>\n",
       "      <th>meantempm_3</th>\n",
       "      <th>meandewptm_1</th>\n",
       "      <th>meandewptm_2</th>\n",
       "      <th>meandewptm_3</th>\n",
       "      <th>meanpressurem_1</th>\n",
       "      <th>meanpressurem_2</th>\n",
       "      <th>meanpressurem_3</th>\n",
       "      <th>maxhumidity_1</th>\n",
       "      <th>...</th>\n",
       "      <th>mindewptm_3</th>\n",
       "      <th>maxpressurem_1</th>\n",
       "      <th>maxpressurem_2</th>\n",
       "      <th>maxpressurem_3</th>\n",
       "      <th>minpressurem_1</th>\n",
       "      <th>minpressurem_2</th>\n",
       "      <th>minpressurem_3</th>\n",
       "      <th>precipm_1</th>\n",
       "      <th>precipm_2</th>\n",
       "      <th>precipm_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-04</th>\n",
       "      <td>-4.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-05</th>\n",
       "      <td>-14.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1033.0</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>1043.0</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-06</th>\n",
       "      <td>-9.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>1033.0</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>1043.0</td>\n",
       "      <td>1043.0</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-07</th>\n",
       "      <td>-10.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>1036.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>1033.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>1043.0</td>\n",
       "      <td>1043.0</td>\n",
       "      <td>1043.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-08</th>\n",
       "      <td>-16.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>1036.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>1043.0</td>\n",
       "      <td>1043.0</td>\n",
       "      <td>956.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-09</th>\n",
       "      <td>-7.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>1036.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>1043.0</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>956.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-10</th>\n",
       "      <td>-11.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>1039.0</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>956.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-11</th>\n",
       "      <td>-6.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>1031.0</td>\n",
       "      <td>1039.0</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-12</th>\n",
       "      <td>-5.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>1031.0</td>\n",
       "      <td>1031.0</td>\n",
       "      <td>1039.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-13</th>\n",
       "      <td>-13.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>1044.0</td>\n",
       "      <td>1031.0</td>\n",
       "      <td>1031.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-14</th>\n",
       "      <td>-12.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>1043.0</td>\n",
       "      <td>1044.0</td>\n",
       "      <td>1031.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-15</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>1043.0</td>\n",
       "      <td>1044.0</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>1043.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-17</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-18</th>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-19</th>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-20</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-21</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-22</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-23</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1031.0</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>1031.0</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-25</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>1031.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-26</th>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-27</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-28</th>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-29</th>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-30</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>1036.0</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-31</th>\n",
       "      <td>-3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1036.0</td>\n",
       "      <td>1036.0</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-01</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>1036.0</td>\n",
       "      <td>1036.0</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>20.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-02</th>\n",
       "      <td>-8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>1031.0</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>1036.0</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>10.16</td>\n",
       "      <td>20.83</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-29</th>\n",
       "      <td>20.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-30</th>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-01</th>\n",
       "      <td>22.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-02</th>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-03</th>\n",
       "      <td>24.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-04</th>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-05</th>\n",
       "      <td>22.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-06</th>\n",
       "      <td>16.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-07</th>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-08</th>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-09</th>\n",
       "      <td>21.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-10</th>\n",
       "      <td>22.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-11</th>\n",
       "      <td>24.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-12</th>\n",
       "      <td>23.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-13</th>\n",
       "      <td>22.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-14</th>\n",
       "      <td>23.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-15</th>\n",
       "      <td>27.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-16</th>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-17</th>\n",
       "      <td>19.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>4.32</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-18</th>\n",
       "      <td>16.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.32</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-19</th>\n",
       "      <td>21.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>6.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-20</th>\n",
       "      <td>26.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.86</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-21</th>\n",
       "      <td>22.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-22</th>\n",
       "      <td>25.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-23</th>\n",
       "      <td>30.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-24</th>\n",
       "      <td>28.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-25</th>\n",
       "      <td>24.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>14.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-26</th>\n",
       "      <td>16.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>20.07</td>\n",
       "      <td>14.99</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-27</th>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.07</td>\n",
       "      <td>14.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>997 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            meantempm_1  meantempm_2  meantempm_3  meandewptm_1  meandewptm_2  \\\n",
       "date                                                                            \n",
       "2015-01-04         -4.0         -6.0         -6.0         -11.0          -9.0   \n",
       "2015-01-05        -14.0         -4.0         -6.0         -19.0         -11.0   \n",
       "2015-01-06         -9.0        -14.0         -4.0         -14.0         -19.0   \n",
       "2015-01-07        -10.0         -9.0        -14.0         -15.0         -14.0   \n",
       "2015-01-08        -16.0        -10.0         -9.0         -22.0         -15.0   \n",
       "2015-01-09         -7.0        -16.0        -10.0         -12.0         -22.0   \n",
       "2015-01-10        -11.0         -7.0        -16.0         -19.0         -12.0   \n",
       "2015-01-11         -6.0        -11.0         -7.0         -12.0         -19.0   \n",
       "2015-01-12         -5.0         -6.0        -11.0         -11.0         -12.0   \n",
       "2015-01-13        -13.0         -5.0         -6.0         -17.0         -11.0   \n",
       "2015-01-14        -12.0        -13.0         -5.0         -18.0         -17.0   \n",
       "2015-01-15         -2.0        -12.0        -13.0          -8.0         -18.0   \n",
       "2015-01-16          1.0         -2.0        -12.0          -6.0          -8.0   \n",
       "2015-01-17          4.0          1.0         -2.0          -4.0          -6.0   \n",
       "2015-01-18          7.0          4.0          1.0          -3.0          -4.0   \n",
       "2015-01-19          4.0          7.0          4.0          -4.0          -3.0   \n",
       "2015-01-20          5.0          4.0          7.0          -3.0          -4.0   \n",
       "2015-01-21          4.0          5.0          4.0          -3.0          -3.0   \n",
       "2015-01-22          2.0          4.0          5.0          -3.0          -3.0   \n",
       "2015-01-23         -1.0          2.0          4.0          -5.0          -3.0   \n",
       "2015-01-24          1.0         -1.0          2.0          -6.0          -5.0   \n",
       "2015-01-25          6.0          1.0         -1.0          -1.0          -6.0   \n",
       "2015-01-26          3.0          6.0          1.0          -1.0          -1.0   \n",
       "2015-01-27          7.0          3.0          6.0          -1.0          -1.0   \n",
       "2015-01-28          4.0          7.0          3.0          -2.0          -1.0   \n",
       "2015-01-29          9.0          4.0          7.0           0.0          -2.0   \n",
       "2015-01-30         -1.0          9.0          4.0          -3.0           0.0   \n",
       "2015-01-31         -3.0         -1.0          9.0          -6.0          -3.0   \n",
       "2015-02-01          2.0         -3.0         -1.0           0.0          -6.0   \n",
       "2015-02-02         -8.0          2.0         -3.0         -10.0           0.0   \n",
       "...                 ...          ...          ...           ...           ...   \n",
       "2017-08-29         20.0         23.0         25.0          15.0          19.0   \n",
       "2017-08-30         19.0         20.0         23.0          14.0          15.0   \n",
       "2017-08-31         20.0         19.0         20.0          14.0          14.0   \n",
       "2017-09-01         22.0         20.0         19.0          16.0          14.0   \n",
       "2017-09-02         22.0         22.0         20.0          17.0          16.0   \n",
       "2017-09-03         24.0         22.0         22.0          18.0          17.0   \n",
       "2017-09-04         24.0         24.0         22.0          18.0          18.0   \n",
       "2017-09-05         22.0         24.0         24.0          15.0          18.0   \n",
       "2017-09-06         16.0         22.0         24.0           7.0          15.0   \n",
       "2017-09-07         14.0         16.0         22.0           7.0           7.0   \n",
       "2017-09-08         18.0         14.0         16.0           8.0           7.0   \n",
       "2017-09-09         21.0         18.0         14.0          12.0           8.0   \n",
       "2017-09-10         22.0         21.0         18.0          13.0          12.0   \n",
       "2017-09-11         24.0         22.0         21.0          14.0          13.0   \n",
       "2017-09-12         23.0         24.0         22.0          13.0          14.0   \n",
       "2017-09-13         22.0         23.0         24.0          14.0          13.0   \n",
       "2017-09-14         23.0         22.0         23.0          13.0          14.0   \n",
       "2017-09-15         27.0         23.0         22.0          13.0          13.0   \n",
       "2017-09-16         27.0         27.0         23.0          15.0          13.0   \n",
       "2017-09-17         19.0         27.0         27.0          17.0          15.0   \n",
       "2017-09-18         16.0         19.0         27.0           9.0          17.0   \n",
       "2017-09-19         21.0         16.0         19.0          18.0           9.0   \n",
       "2017-09-20         26.0         21.0         16.0          19.0          18.0   \n",
       "2017-09-21         22.0         26.0         21.0          13.0          19.0   \n",
       "2017-09-22         25.0         22.0         26.0          18.0          13.0   \n",
       "2017-09-23         30.0         25.0         22.0          20.0          18.0   \n",
       "2017-09-24         28.0         30.0         25.0          18.0          20.0   \n",
       "2017-09-25         24.0         28.0         30.0          18.0          18.0   \n",
       "2017-09-26         16.0         24.0         28.0          15.0          18.0   \n",
       "2017-09-27         15.0         16.0         24.0          11.0          15.0   \n",
       "\n",
       "            meandewptm_3  meanpressurem_1  meanpressurem_2  meanpressurem_3  \\\n",
       "date                                                                          \n",
       "2015-01-04         -12.0           1016.0           1022.0           1023.0   \n",
       "2015-01-05          -9.0           1033.0           1016.0           1022.0   \n",
       "2015-01-06         -11.0           1032.0           1033.0           1016.0   \n",
       "2015-01-07         -19.0           1036.0           1032.0           1033.0   \n",
       "2015-01-08         -14.0           1035.0           1036.0           1032.0   \n",
       "2015-01-09         -15.0           1024.0           1035.0           1036.0   \n",
       "2015-01-10         -22.0           1035.0           1024.0           1035.0   \n",
       "2015-01-11         -12.0           1023.0           1035.0           1024.0   \n",
       "2015-01-12         -19.0           1024.0           1023.0           1035.0   \n",
       "2015-01-13         -12.0           1040.0           1024.0           1023.0   \n",
       "2015-01-14         -11.0           1037.0           1040.0           1024.0   \n",
       "2015-01-15         -17.0           1026.0           1037.0           1040.0   \n",
       "2015-01-16         -18.0           1023.0           1026.0           1037.0   \n",
       "2015-01-17          -8.0           1014.0           1023.0           1026.0   \n",
       "2015-01-18          -6.0           1012.0           1014.0           1023.0   \n",
       "2015-01-19          -4.0           1015.0           1012.0           1014.0   \n",
       "2015-01-20          -3.0           1015.0           1015.0           1012.0   \n",
       "2015-01-21          -4.0           1018.0           1015.0           1015.0   \n",
       "2015-01-22          -3.0           1025.0           1018.0           1015.0   \n",
       "2015-01-23          -3.0           1031.0           1025.0           1018.0   \n",
       "2015-01-24          -3.0           1020.0           1031.0           1025.0   \n",
       "2015-01-25          -5.0           1010.0           1020.0           1031.0   \n",
       "2015-01-26          -6.0           1014.0           1010.0           1020.0   \n",
       "2015-01-27          -1.0           1016.0           1014.0           1010.0   \n",
       "2015-01-28          -1.0           1019.0           1016.0           1014.0   \n",
       "2015-01-29          -1.0           1010.0           1019.0           1016.0   \n",
       "2015-01-30          -2.0           1029.0           1010.0           1019.0   \n",
       "2015-01-31           0.0           1032.0           1029.0           1010.0   \n",
       "2015-02-01          -3.0           1018.0           1032.0           1029.0   \n",
       "2015-02-02          -6.0           1018.0           1018.0           1032.0   \n",
       "...                  ...              ...              ...              ...   \n",
       "2017-08-29          19.0           1019.0           1017.0           1017.0   \n",
       "2017-08-30          19.0           1019.0           1019.0           1017.0   \n",
       "2017-08-31          15.0           1019.0           1019.0           1019.0   \n",
       "2017-09-01          14.0           1019.0           1019.0           1019.0   \n",
       "2017-09-02          14.0           1017.0           1019.0           1019.0   \n",
       "2017-09-03          16.0           1016.0           1017.0           1019.0   \n",
       "2017-09-04          17.0           1016.0           1016.0           1017.0   \n",
       "2017-09-05          18.0           1014.0           1016.0           1016.0   \n",
       "2017-09-06          18.0           1022.0           1014.0           1016.0   \n",
       "2017-09-07          15.0           1022.0           1022.0           1014.0   \n",
       "2017-09-08           7.0           1019.0           1022.0           1022.0   \n",
       "2017-09-09           7.0           1017.0           1019.0           1022.0   \n",
       "2017-09-10           8.0           1021.0           1017.0           1019.0   \n",
       "2017-09-11          12.0           1022.0           1021.0           1017.0   \n",
       "2017-09-12          13.0           1020.0           1022.0           1021.0   \n",
       "2017-09-13          14.0           1014.0           1020.0           1022.0   \n",
       "2017-09-14          13.0           1008.0           1014.0           1020.0   \n",
       "2017-09-15          14.0           1005.0           1008.0           1014.0   \n",
       "2017-09-16          13.0           1006.0           1005.0           1008.0   \n",
       "2017-09-17          13.0           1012.0           1006.0           1005.0   \n",
       "2017-09-18          15.0           1021.0           1012.0           1006.0   \n",
       "2017-09-19          17.0           1014.0           1021.0           1012.0   \n",
       "2017-09-20           9.0           1005.0           1014.0           1021.0   \n",
       "2017-09-21          18.0           1007.0           1005.0           1014.0   \n",
       "2017-09-22          19.0           1008.0           1007.0           1005.0   \n",
       "2017-09-23          13.0           1008.0           1008.0           1007.0   \n",
       "2017-09-24          18.0           1011.0           1008.0           1008.0   \n",
       "2017-09-25          20.0           1012.0           1011.0           1008.0   \n",
       "2017-09-26          18.0           1014.0           1012.0           1011.0   \n",
       "2017-09-27          18.0           1019.0           1014.0           1012.0   \n",
       "\n",
       "            maxhumidity_1    ...      mindewptm_3  maxpressurem_1  \\\n",
       "date                         ...                                    \n",
       "2015-01-04           92.0    ...            -18.0          1025.0   \n",
       "2015-01-05           80.0    ...            -13.0          1043.0   \n",
       "2015-01-06           80.0    ...            -16.0          1043.0   \n",
       "2015-01-07           80.0    ...            -23.0          1043.0   \n",
       "2015-01-08           72.0    ...            -17.0          1055.0   \n",
       "2015-01-09           69.0    ...            -18.0          1037.0   \n",
       "2015-01-10           69.0    ...            -24.0          1039.0   \n",
       "2015-01-11           79.0    ...            -21.0          1031.0   \n",
       "2015-01-12           96.0    ...            -21.0          1031.0   \n",
       "2015-01-13           87.0    ...            -19.0          1044.0   \n",
       "2015-01-14           87.0    ...            -14.0          1043.0   \n",
       "2015-01-15           84.0    ...            -21.0          1030.0   \n",
       "2015-01-16           91.0    ...            -23.0          1024.0   \n",
       "2015-01-17           96.0    ...            -15.0          1022.0   \n",
       "2015-01-18           65.0    ...            -10.0          1016.0   \n",
       "2015-01-19           85.0    ...             -7.0          1017.0   \n",
       "2015-01-20           84.0    ...             -5.0          1017.0   \n",
       "2015-01-21           78.0    ...             -7.0          1020.0   \n",
       "2015-01-22           85.0    ...             -6.0          1030.0   \n",
       "2015-01-23           85.0    ...             -5.0          1034.0   \n",
       "2015-01-24           84.0    ...             -5.0          1027.0   \n",
       "2015-01-25           85.0    ...             -8.0          1017.0   \n",
       "2015-01-26           85.0    ...             -9.0          1020.0   \n",
       "2015-01-27           92.0    ...             -4.0          1019.0   \n",
       "2015-01-28           92.0    ...             -3.0          1022.0   \n",
       "2015-01-29           85.0    ...             -4.0          1016.0   \n",
       "2015-01-30           81.0    ...             -8.0          1036.0   \n",
       "2015-01-31           92.0    ...             -3.0          1036.0   \n",
       "2015-02-01           96.0    ...             -8.0          1025.0   \n",
       "2015-02-02           92.0    ...            -13.0          1031.0   \n",
       "...                   ...    ...              ...             ...   \n",
       "2017-08-29           93.0    ...             16.0          1021.0   \n",
       "2017-08-30          100.0    ...             17.0          1020.0   \n",
       "2017-08-31           93.0    ...             13.0          1021.0   \n",
       "2017-09-01           93.0    ...             12.0          1021.0   \n",
       "2017-09-02           93.0    ...             11.0          1019.0   \n",
       "2017-09-03          100.0    ...             13.0          1017.0   \n",
       "2017-09-04          100.0    ...             15.0          1019.0   \n",
       "2017-09-05           81.0    ...             17.0          1020.0   \n",
       "2017-09-06           86.0    ...             15.0          1023.0   \n",
       "2017-09-07           93.0    ...             12.0          1023.0   \n",
       "2017-09-08           92.0    ...              4.0          1021.0   \n",
       "2017-09-09           89.0    ...              4.0          1019.0   \n",
       "2017-09-10           80.0    ...              6.0          1023.0   \n",
       "2017-09-11           78.0    ...             10.0          1025.0   \n",
       "2017-09-12           87.0    ...             11.0          1022.0   \n",
       "2017-09-13           93.0    ...             13.0          1018.0   \n",
       "2017-09-14           93.0    ...             12.0          1011.0   \n",
       "2017-09-15           73.0    ...             12.0          1007.0   \n",
       "2017-09-16           73.0    ...             12.0          1008.0   \n",
       "2017-09-17           90.0    ...             11.0          1019.0   \n",
       "2017-09-18           93.0    ...             13.0          1024.0   \n",
       "2017-09-19          100.0    ...             12.0          1019.0   \n",
       "2017-09-20           93.0    ...              7.0          1011.0   \n",
       "2017-09-21           79.0    ...             14.0          1011.0   \n",
       "2017-09-22           87.0    ...             18.0          1011.0   \n",
       "2017-09-23           82.0    ...             10.0          1010.0   \n",
       "2017-09-24           90.0    ...             11.0          1013.0   \n",
       "2017-09-25           93.0    ...             17.0          1015.0   \n",
       "2017-09-26           97.0    ...             16.0          1015.0   \n",
       "2017-09-27           93.0    ...             17.0          1022.0   \n",
       "\n",
       "            maxpressurem_2  maxpressurem_3  minpressurem_1  minpressurem_2  \\\n",
       "date                                                                         \n",
       "2015-01-04          1026.0          1025.0          1010.0          1017.0   \n",
       "2015-01-05          1025.0          1026.0          1023.0          1010.0   \n",
       "2015-01-06          1043.0          1025.0          1023.0          1023.0   \n",
       "2015-01-07          1043.0          1043.0          1027.0          1023.0   \n",
       "2015-01-08          1043.0          1043.0           956.0          1027.0   \n",
       "2015-01-09          1055.0          1043.0          1014.0           956.0   \n",
       "2015-01-10          1037.0          1055.0          1030.0          1014.0   \n",
       "2015-01-11          1039.0          1037.0          1019.0          1030.0   \n",
       "2015-01-12          1031.0          1039.0          1021.0          1019.0   \n",
       "2015-01-13          1031.0          1031.0          1032.0          1021.0   \n",
       "2015-01-14          1044.0          1031.0          1032.0          1032.0   \n",
       "2015-01-15          1043.0          1044.0          1023.0          1032.0   \n",
       "2015-01-16          1030.0          1043.0          1021.0          1023.0   \n",
       "2015-01-17          1024.0          1030.0          1008.0          1021.0   \n",
       "2015-01-18          1022.0          1024.0          1006.0          1008.0   \n",
       "2015-01-19          1016.0          1022.0          1012.0          1006.0   \n",
       "2015-01-20          1017.0          1016.0          1013.0          1012.0   \n",
       "2015-01-21          1017.0          1017.0          1016.0          1013.0   \n",
       "2015-01-22          1020.0          1017.0          1021.0          1016.0   \n",
       "2015-01-23          1030.0          1020.0          1028.0          1021.0   \n",
       "2015-01-24          1034.0          1030.0          1015.0          1028.0   \n",
       "2015-01-25          1027.0          1034.0          1005.0          1015.0   \n",
       "2015-01-26          1017.0          1027.0          1005.0          1005.0   \n",
       "2015-01-27          1020.0          1017.0          1014.0          1005.0   \n",
       "2015-01-28          1019.0          1020.0          1015.0          1014.0   \n",
       "2015-01-29          1022.0          1019.0          1005.0          1015.0   \n",
       "2015-01-30          1016.0          1022.0          1019.0          1005.0   \n",
       "2015-01-31          1036.0          1016.0          1026.0          1019.0   \n",
       "2015-02-01          1036.0          1036.0          1011.0          1026.0   \n",
       "2015-02-02          1025.0          1036.0          1009.0          1011.0   \n",
       "...                    ...             ...             ...             ...   \n",
       "2017-08-29          1019.0          1019.0          1018.0          1015.0   \n",
       "2017-08-30          1021.0          1019.0          1018.0          1018.0   \n",
       "2017-08-31          1020.0          1021.0          1018.0          1018.0   \n",
       "2017-09-01          1021.0          1020.0          1017.0          1018.0   \n",
       "2017-09-02          1021.0          1021.0          1016.0          1017.0   \n",
       "2017-09-03          1019.0          1021.0          1015.0          1016.0   \n",
       "2017-09-04          1017.0          1019.0          1010.0          1015.0   \n",
       "2017-09-05          1019.0          1017.0          1009.0          1010.0   \n",
       "2017-09-06          1020.0          1019.0          1021.0          1009.0   \n",
       "2017-09-07          1023.0          1020.0          1021.0          1021.0   \n",
       "2017-09-08          1023.0          1023.0          1015.0          1021.0   \n",
       "2017-09-09          1021.0          1023.0          1016.0          1015.0   \n",
       "2017-09-10          1019.0          1021.0          1019.0          1016.0   \n",
       "2017-09-11          1023.0          1019.0          1020.0          1019.0   \n",
       "2017-09-12          1025.0          1023.0          1018.0          1020.0   \n",
       "2017-09-13          1022.0          1025.0          1010.0          1018.0   \n",
       "2017-09-14          1018.0          1022.0          1005.0          1010.0   \n",
       "2017-09-15          1011.0          1018.0          1003.0          1005.0   \n",
       "2017-09-16          1007.0          1011.0          1005.0          1003.0   \n",
       "2017-09-17          1008.0          1007.0          1009.0          1005.0   \n",
       "2017-09-18          1019.0          1008.0          1018.0          1009.0   \n",
       "2017-09-19          1024.0          1019.0          1011.0          1018.0   \n",
       "2017-09-20          1019.0          1024.0           999.0          1011.0   \n",
       "2017-09-21          1011.0          1019.0          1000.0           999.0   \n",
       "2017-09-22          1011.0          1011.0          1005.0          1000.0   \n",
       "2017-09-23          1011.0          1011.0          1007.0          1005.0   \n",
       "2017-09-24          1010.0          1011.0          1010.0          1007.0   \n",
       "2017-09-25          1013.0          1010.0          1010.0          1010.0   \n",
       "2017-09-26          1015.0          1013.0          1012.0          1010.0   \n",
       "2017-09-27          1015.0          1015.0          1015.0          1012.0   \n",
       "\n",
       "            minpressurem_3  precipm_1  precipm_2  precipm_3  \n",
       "date                                                         \n",
       "2015-01-04          1019.0       0.76       0.00       0.00  \n",
       "2015-01-05          1017.0       0.25       0.76       0.00  \n",
       "2015-01-06          1010.0       0.00       0.25       0.76  \n",
       "2015-01-07          1023.0       0.00       0.00       0.25  \n",
       "2015-01-08          1023.0       0.00       0.00       0.00  \n",
       "2015-01-09          1027.0       0.00       0.00       0.00  \n",
       "2015-01-10           956.0       0.00       0.00       0.00  \n",
       "2015-01-11          1014.0       0.00       0.00       0.00  \n",
       "2015-01-12          1030.0       0.00       0.00       0.00  \n",
       "2015-01-13          1019.0       0.00       0.00       0.00  \n",
       "2015-01-14          1021.0       0.00       0.00       0.00  \n",
       "2015-01-15          1032.0       0.00       0.00       0.00  \n",
       "2015-01-16          1032.0       0.00       0.00       0.00  \n",
       "2015-01-17          1023.0       0.00       0.00       0.00  \n",
       "2015-01-18          1021.0       0.00       0.00       0.00  \n",
       "2015-01-19          1008.0       0.00       0.00       0.00  \n",
       "2015-01-20          1006.0       0.00       0.00       0.00  \n",
       "2015-01-21          1012.0       0.00       0.00       0.00  \n",
       "2015-01-22          1013.0       0.00       0.00       0.00  \n",
       "2015-01-23          1016.0       0.00       0.00       0.00  \n",
       "2015-01-24          1021.0       0.00       0.00       0.00  \n",
       "2015-01-25          1028.0       0.76       0.00       0.00  \n",
       "2015-01-26          1015.0       0.00       0.76       0.00  \n",
       "2015-01-27          1005.0       0.00       0.00       0.76  \n",
       "2015-01-28          1005.0       0.00       0.00       0.00  \n",
       "2015-01-29          1014.0       0.00       0.00       0.00  \n",
       "2015-01-30          1015.0       0.00       0.00       0.00  \n",
       "2015-01-31          1005.0       0.00       0.00       0.00  \n",
       "2015-02-01          1019.0      20.83       0.00       0.00  \n",
       "2015-02-02          1026.0      10.16      20.83       0.00  \n",
       "...                    ...        ...        ...        ...  \n",
       "2017-08-29          1015.0       0.00       2.03       0.00  \n",
       "2017-08-30          1015.0       0.00       0.00       2.03  \n",
       "2017-08-31          1018.0       0.00       0.00       0.00  \n",
       "2017-09-01          1018.0       0.00       0.00       0.00  \n",
       "2017-09-02          1018.0       0.25       0.00       0.00  \n",
       "2017-09-03          1017.0       0.00       0.25       0.00  \n",
       "2017-09-04          1016.0       0.00       0.00       0.25  \n",
       "2017-09-05          1015.0       0.00       0.00       0.00  \n",
       "2017-09-06          1010.0       0.00       0.00       0.00  \n",
       "2017-09-07          1009.0       0.00       0.00       0.00  \n",
       "2017-09-08          1021.0       0.00       0.00       0.00  \n",
       "2017-09-09          1021.0       0.00       0.00       0.00  \n",
       "2017-09-10          1015.0       0.00       0.00       0.00  \n",
       "2017-09-11          1016.0       0.00       0.00       0.00  \n",
       "2017-09-12          1019.0       0.00       0.00       0.00  \n",
       "2017-09-13          1020.0       0.00       0.00       0.00  \n",
       "2017-09-14          1018.0       0.00       0.00       0.00  \n",
       "2017-09-15          1010.0       0.00       0.00       0.00  \n",
       "2017-09-16          1005.0       0.25       0.00       0.00  \n",
       "2017-09-17          1003.0       4.32       0.25       0.00  \n",
       "2017-09-18          1005.0       0.00       4.32       0.25  \n",
       "2017-09-19          1009.0       6.86       0.00       4.32  \n",
       "2017-09-20          1018.0       0.00       6.86       0.00  \n",
       "2017-09-21          1011.0       0.00       0.00       6.86  \n",
       "2017-09-22           999.0       0.00       0.00       0.00  \n",
       "2017-09-23          1000.0       0.00       0.00       0.00  \n",
       "2017-09-24          1005.0       0.00       0.00       0.00  \n",
       "2017-09-25          1007.0      14.99       0.00       0.00  \n",
       "2017-09-26          1010.0      20.07      14.99       0.00  \n",
       "2017-09-27          1010.0       0.00      20.07      14.99  \n",
       "\n",
       "[997 rows x 36 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training set and a temporary set using sklearn.model_selection.traing_test_split\n",
    "X_train, X_tmp, y_train, y_tmp = train_test_split(X, y, test_size=0.2, random_state=23)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training instances   797, Training features   36\n",
      "Validation instances 100, Validation features 36\n",
      "Testing instances    100, Testing features    36\n"
     ]
    }
   ],
   "source": [
    "# take the remaining 20% of data in X_tmp, y_tmp and split them evenly\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_tmp, y_tmp, test_size=0.5, random_state=23)\n",
    "\n",
    "X_train.shape, X_test.shape, X_val.shape  \n",
    "print(\"Training instances   {}, Training features   {}\".format(X_train.shape[0], X_train.shape[1]))  \n",
    "print(\"Validation instances {}, Validation features {}\".format(X_val.shape[0], X_val.shape[1]))  \n",
    "print(\"Testing instances    {}, Testing features    {}\".format(X_test.shape[0], X_test.shape[1]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [tf.feature_column.numeric_column(col) for col in X.columns]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'tf_wx_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002860680D5C0>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "regressor = tf.estimator.DNNRegressor(feature_columns=feature_cols,  \n",
    "                                      hidden_units=[50, 50],\n",
    "                                      model_dir='tf_wx_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wx_input_fn(X, y=None, num_epochs=None, shuffle=True, batch_size=400):  \n",
    "    return tf.estimator.inputs.pandas_input_fn(x=X,\n",
    "                                               y=y,\n",
    "                                               num_epochs=num_epochs,\n",
    "                                               shuffle=shuffle,\n",
    "                                               batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 58768.3, step = 1\n",
      "INFO:tensorflow:global_step/sec: 62.4055\n",
      "INFO:tensorflow:loss = 11380.6, step = 101 (1.602 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.9823\n",
      "INFO:tensorflow:loss = 8710.69, step = 201 (1.487 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.1236\n",
      "INFO:tensorflow:loss = 8700.92, step = 301 (1.539 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 400 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 7761.3.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-11:51:52\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-400\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-11:51:53\n",
      "INFO:tensorflow:Saving dict for global step 400: average_loss = 17.1875, global_step = 400, loss = 1718.75\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-400\n",
      "INFO:tensorflow:Saving checkpoints for 401 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 8268.11, step = 401\n",
      "INFO:tensorflow:global_step/sec: 63.231\n",
      "INFO:tensorflow:loss = 7402.38, step = 501 (1.582 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.1975\n",
      "INFO:tensorflow:loss = 7755.98, step = 601 (1.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.5783\n",
      "INFO:tensorflow:loss = 7612.59, step = 701 (1.502 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 800 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 7799.35.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-11:52:07\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-800\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-11:52:08\n",
      "INFO:tensorflow:Saving dict for global step 800: average_loss = 14.8771, global_step = 800, loss = 1487.71\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-800\n",
      "INFO:tensorflow:Saving checkpoints for 801 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 7071.81, step = 801\n",
      "INFO:tensorflow:global_step/sec: 65.2226\n",
      "INFO:tensorflow:loss = 6955.6, step = 901 (1.547 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.5587\n",
      "INFO:tensorflow:loss = 6761.67, step = 1001 (1.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.2359\n",
      "INFO:tensorflow:loss = 7747.5, step = 1101 (1.472 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1200 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6701.41.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-11:52:20\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-1200\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-11:52:21\n",
      "INFO:tensorflow:Saving dict for global step 1200: average_loss = 13.7795, global_step = 1200, loss = 1377.95\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-1200\n",
      "INFO:tensorflow:Saving checkpoints for 1201 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 7496.8, step = 1201\n",
      "INFO:tensorflow:global_step/sec: 63.0258\n",
      "INFO:tensorflow:loss = 7277.1, step = 1301 (1.587 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.4972\n",
      "INFO:tensorflow:loss = 7056.7, step = 1401 (1.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.5852\n",
      "INFO:tensorflow:loss = 6598.42, step = 1501 (1.464 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1600 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 7138.08.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-11:52:33\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-1600\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-11:52:33\n",
      "INFO:tensorflow:Saving dict for global step 1600: average_loss = 13.1574, global_step = 1600, loss = 1315.74\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-1600\n",
      "INFO:tensorflow:Saving checkpoints for 1601 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 6588.87, step = 1601\n",
      "INFO:tensorflow:global_step/sec: 63.6707\n",
      "INFO:tensorflow:loss = 6753.59, step = 1701 (1.569 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.9668\n",
      "INFO:tensorflow:loss = 6117.74, step = 1801 (1.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.2551\n",
      "INFO:tensorflow:loss = 6007.38, step = 1901 (1.503 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6611.37.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-11:52:45\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-2000\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-11:52:46\n",
      "INFO:tensorflow:Saving dict for global step 2000: average_loss = 12.6402, global_step = 2000, loss = 1264.02\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-2000\n",
      "INFO:tensorflow:Saving checkpoints for 2001 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 6001.33, step = 2001\n",
      "INFO:tensorflow:global_step/sec: 63.6088\n",
      "INFO:tensorflow:loss = 6589.06, step = 2101 (1.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.9813\n",
      "INFO:tensorflow:loss = 6501.68, step = 2201 (1.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.9517\n",
      "INFO:tensorflow:loss = 6446.03, step = 2301 (1.516 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2400 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5920.8.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-11:52:58\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-2400\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-11:52:59\n",
      "INFO:tensorflow:Saving dict for global step 2400: average_loss = 12.378, global_step = 2400, loss = 1237.8\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-2400\n",
      "INFO:tensorflow:Saving checkpoints for 2401 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 6341.5, step = 2401\n",
      "INFO:tensorflow:global_step/sec: 63.001\n",
      "INFO:tensorflow:loss = 5736.09, step = 2501 (1.587 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.8967\n",
      "INFO:tensorflow:loss = 5477.69, step = 2601 (1.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.3371\n",
      "INFO:tensorflow:loss = 5654.19, step = 2701 (1.499 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2800 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6296.99.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-11:53:11\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-2800\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-11:53:12\n",
      "INFO:tensorflow:Saving dict for global step 2800: average_loss = 12.0111, global_step = 2800, loss = 1201.11\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-2800\n",
      "INFO:tensorflow:Saving checkpoints for 2801 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 6267.49, step = 2801\n",
      "INFO:tensorflow:global_step/sec: 63.6023\n",
      "INFO:tensorflow:loss = 6182.97, step = 2901 (1.572 sec)\n",
      "INFO:tensorflow:global_step/sec: 59.4917\n",
      "INFO:tensorflow:loss = 5852.32, step = 3001 (1.681 sec)\n",
      "INFO:tensorflow:global_step/sec: 60.3659\n",
      "INFO:tensorflow:loss = 6190.39, step = 3101 (1.657 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3200 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5849.34.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-11:53:24\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-3200\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-11:53:25\n",
      "INFO:tensorflow:Saving dict for global step 3200: average_loss = 11.8665, global_step = 3200, loss = 1186.65\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-3200\n",
      "INFO:tensorflow:Saving checkpoints for 3201 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5678.65, step = 3201\n",
      "INFO:tensorflow:global_step/sec: 64.366\n",
      "INFO:tensorflow:loss = 6029.29, step = 3301 (1.570 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.7934\n",
      "INFO:tensorflow:loss = 6360.7, step = 3401 (1.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.201\n",
      "INFO:tensorflow:loss = 6190.64, step = 3501 (1.488 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3600 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5504.17.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-11:53:37\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-3600\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-11:53:38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 3600: average_loss = 11.6401, global_step = 3600, loss = 1164.01\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-3600\n",
      "INFO:tensorflow:Saving checkpoints for 3601 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 6123.55, step = 3601\n",
      "INFO:tensorflow:global_step/sec: 63.7119\n",
      "INFO:tensorflow:loss = 5602.12, step = 3701 (1.570 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.9115\n",
      "INFO:tensorflow:loss = 5423.4, step = 3801 (1.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.6101\n",
      "INFO:tensorflow:loss = 5780.98, step = 3901 (1.501 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5866.5.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-11:53:50\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-4000\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-11:53:51\n",
      "INFO:tensorflow:Saving dict for global step 4000: average_loss = 11.7001, global_step = 4000, loss = 1170.01\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-4000\n",
      "INFO:tensorflow:Saving checkpoints for 4001 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5556.97, step = 4001\n",
      "INFO:tensorflow:global_step/sec: 63.7354\n",
      "INFO:tensorflow:loss = 6027.53, step = 4101 (1.572 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.4231\n",
      "INFO:tensorflow:loss = 6024.07, step = 4201 (1.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.6465\n",
      "INFO:tensorflow:loss = 6108.7, step = 4301 (1.518 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4400 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6445.89.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-11:54:03\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-4400\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-11:54:04\n",
      "INFO:tensorflow:Saving dict for global step 4400: average_loss = 11.5858, global_step = 4400, loss = 1158.58\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-4400\n",
      "INFO:tensorflow:Saving checkpoints for 4401 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 6153.47, step = 4401\n",
      "INFO:tensorflow:global_step/sec: 62.4005\n",
      "INFO:tensorflow:loss = 6009.84, step = 4501 (1.618 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.2177\n",
      "INFO:tensorflow:loss = 5309.63, step = 4601 (1.518 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.1718\n",
      "INFO:tensorflow:loss = 5487.43, step = 4701 (1.489 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4800 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5733.84.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-11:54:16\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-4800\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-11:54:17\n",
      "INFO:tensorflow:Saving dict for global step 4800: average_loss = 11.3247, global_step = 4800, loss = 1132.47\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-4800\n",
      "INFO:tensorflow:Saving checkpoints for 4801 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5512.95, step = 4801\n",
      "INFO:tensorflow:global_step/sec: 64.4509\n",
      "INFO:tensorflow:loss = 5862.03, step = 4901 (1.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.4649\n",
      "INFO:tensorflow:loss = 5263.93, step = 5001 (1.548 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.9633\n",
      "INFO:tensorflow:loss = 5599.05, step = 5101 (1.516 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5200 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5549.64.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-11:54:29\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-5200\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-11:54:30\n",
      "INFO:tensorflow:Saving dict for global step 5200: average_loss = 11.2792, global_step = 5200, loss = 1127.92\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-5200\n",
      "INFO:tensorflow:Saving checkpoints for 5201 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5787.85, step = 5201\n",
      "INFO:tensorflow:global_step/sec: 65.153\n",
      "INFO:tensorflow:loss = 6614.64, step = 5301 (1.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.9147\n",
      "INFO:tensorflow:loss = 5881.71, step = 5401 (1.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.6409\n",
      "INFO:tensorflow:loss = 5754.02, step = 5501 (1.472 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5600 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6028.94.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-11:54:42\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-5600\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-11:54:42\n",
      "INFO:tensorflow:Saving dict for global step 5600: average_loss = 11.2223, global_step = 5600, loss = 1122.23\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-5600\n",
      "INFO:tensorflow:Saving checkpoints for 5601 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 6068.06, step = 5601\n",
      "INFO:tensorflow:global_step/sec: 64.3364\n",
      "INFO:tensorflow:loss = 5123.08, step = 5701 (1.554 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.5964\n",
      "INFO:tensorflow:loss = 5776.9, step = 5801 (1.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.7025\n",
      "INFO:tensorflow:loss = 6255.86, step = 5901 (1.477 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6000 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5158.18.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-11:54:54\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-6000\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-11:54:55\n",
      "INFO:tensorflow:Saving dict for global step 6000: average_loss = 11.1523, global_step = 6000, loss = 1115.23\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-6000\n",
      "INFO:tensorflow:Saving checkpoints for 6001 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5472.52, step = 6001\n",
      "INFO:tensorflow:global_step/sec: 63.0046\n",
      "INFO:tensorflow:loss = 6151.95, step = 6101 (1.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.5769\n",
      "INFO:tensorflow:loss = 5479.15, step = 6201 (1.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.3627\n",
      "INFO:tensorflow:loss = 5617.9, step = 6301 (1.500 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6400 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5376.65.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-11:55:07\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-6400\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-11:55:08\n",
      "INFO:tensorflow:Saving dict for global step 6400: average_loss = 11.0249, global_step = 6400, loss = 1102.49\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-6400\n",
      "INFO:tensorflow:Saving checkpoints for 6401 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 6086.86, step = 6401\n",
      "INFO:tensorflow:global_step/sec: 65.2397\n",
      "INFO:tensorflow:loss = 5639.58, step = 6501 (1.533 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.0339\n",
      "INFO:tensorflow:loss = 5325.84, step = 6601 (1.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.9922\n",
      "INFO:tensorflow:loss = 5467.64, step = 6701 (1.471 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6800 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4868.65.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-11:55:20\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-6800\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-11:55:21\n",
      "INFO:tensorflow:Saving dict for global step 6800: average_loss = 11.0648, global_step = 6800, loss = 1106.48\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-6800\n",
      "INFO:tensorflow:Saving checkpoints for 6801 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 6239.75, step = 6801\n",
      "INFO:tensorflow:global_step/sec: 64.6117\n",
      "INFO:tensorflow:loss = 5613.24, step = 6901 (1.563 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.3123\n",
      "INFO:tensorflow:loss = 4786.38, step = 7001 (1.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.2551\n",
      "INFO:tensorflow:loss = 5020.15, step = 7101 (1.487 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7200 into tf_wx_model\\model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 5671.53.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-11:55:33\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-7200\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-11:55:33\n",
      "INFO:tensorflow:Saving dict for global step 7200: average_loss = 11.0385, global_step = 7200, loss = 1103.85\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-7200\n",
      "INFO:tensorflow:Saving checkpoints for 7201 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5061.91, step = 7201\n",
      "INFO:tensorflow:global_step/sec: 62.9996\n",
      "INFO:tensorflow:loss = 5723.26, step = 7301 (1.587 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.2651\n",
      "INFO:tensorflow:loss = 5999.84, step = 7401 (1.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.1581\n",
      "INFO:tensorflow:loss = 6244.64, step = 7501 (1.531 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7600 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4585.31.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-11:55:46\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-7600\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-11:55:46\n",
      "INFO:tensorflow:Saving dict for global step 7600: average_loss = 10.9102, global_step = 7600, loss = 1091.02\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-7600\n",
      "INFO:tensorflow:Saving checkpoints for 7601 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5429.7, step = 7601\n",
      "INFO:tensorflow:global_step/sec: 62.4727\n",
      "INFO:tensorflow:loss = 5809.03, step = 7701 (1.585 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.2403\n",
      "INFO:tensorflow:loss = 5368.17, step = 7801 (1.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.0583\n",
      "INFO:tensorflow:loss = 5183.56, step = 7901 (1.480 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8000 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5674.67.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-11:55:58\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-8000\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-11:55:59\n",
      "INFO:tensorflow:Saving dict for global step 8000: average_loss = 10.9314, global_step = 8000, loss = 1093.14\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-8000\n",
      "INFO:tensorflow:Saving checkpoints for 8001 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 4953.54, step = 8001\n",
      "INFO:tensorflow:global_step/sec: 64.5829\n",
      "INFO:tensorflow:loss = 5261.21, step = 8101 (1.565 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.2069\n",
      "INFO:tensorflow:loss = 5288.76, step = 8201 (1.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.0296\n",
      "INFO:tensorflow:loss = 4988.96, step = 8301 (1.470 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8400 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5335.83.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-11:56:11\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-8400\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-11:56:12\n",
      "INFO:tensorflow:Saving dict for global step 8400: average_loss = 10.9313, global_step = 8400, loss = 1093.13\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-8400\n",
      "INFO:tensorflow:Saving checkpoints for 8401 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5536.01, step = 8401\n",
      "INFO:tensorflow:global_step/sec: 64.492\n",
      "INFO:tensorflow:loss = 5414.29, step = 8501 (1.550 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.2893\n",
      "INFO:tensorflow:loss = 5446.5, step = 8601 (1.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.5259\n",
      "INFO:tensorflow:loss = 5490.75, step = 8701 (1.503 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8800 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5449.13.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-11:56:24\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-8800\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-11:56:24\n",
      "INFO:tensorflow:Saving dict for global step 8800: average_loss = 10.8475, global_step = 8800, loss = 1084.75\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-8800\n",
      "INFO:tensorflow:Saving checkpoints for 8801 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 4964.63, step = 8801\n",
      "INFO:tensorflow:global_step/sec: 63.7808\n",
      "INFO:tensorflow:loss = 5357.15, step = 8901 (1.571 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.1147\n",
      "INFO:tensorflow:loss = 5603.81, step = 9001 (1.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.5084\n",
      "INFO:tensorflow:loss = 5288.12, step = 9101 (1.504 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9200 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5394.88.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-11:56:37\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-9200\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-11:56:37\n",
      "INFO:tensorflow:Saving dict for global step 9200: average_loss = 10.8095, global_step = 9200, loss = 1080.95\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-9200\n",
      "INFO:tensorflow:Saving checkpoints for 9201 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5063.51, step = 9201\n",
      "INFO:tensorflow:global_step/sec: 63.9903\n",
      "INFO:tensorflow:loss = 5146.72, step = 9301 (1.563 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.279\n",
      "INFO:tensorflow:loss = 5391.45, step = 9401 (1.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.2102\n",
      "INFO:tensorflow:loss = 5171.51, step = 9501 (1.488 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9600 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5891.16.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-11:56:49\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-9600\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-11:56:50\n",
      "INFO:tensorflow:Saving dict for global step 9600: average_loss = 10.8129, global_step = 9600, loss = 1081.29\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-9600\n",
      "INFO:tensorflow:Saving checkpoints for 9601 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 4920.66, step = 9601\n",
      "INFO:tensorflow:global_step/sec: 62.4023\n",
      "INFO:tensorflow:loss = 5666.09, step = 9701 (1.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.0695\n",
      "INFO:tensorflow:loss = 5618.79, step = 9801 (1.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.046\n",
      "INFO:tensorflow:loss = 5564.33, step = 9901 (1.481 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5619.64.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-11:57:02\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-10000\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-11:57:03\n",
      "INFO:tensorflow:Saving dict for global step 10000: average_loss = 10.7784, global_step = 10000, loss = 1077.84\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-10000\n",
      "INFO:tensorflow:Saving checkpoints for 10001 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5550.28, step = 10001\n",
      "INFO:tensorflow:global_step/sec: 65.2138\n",
      "INFO:tensorflow:loss = 5320.82, step = 10101 (1.549 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.8968\n",
      "INFO:tensorflow:loss = 4937.64, step = 10201 (1.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.977\n",
      "INFO:tensorflow:loss = 5713.22, step = 10301 (1.471 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10400 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4701.89.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-11:57:15\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-10400\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-11:57:16\n",
      "INFO:tensorflow:Saving dict for global step 10400: average_loss = 10.7628, global_step = 10400, loss = 1076.28\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-10400\n",
      "INFO:tensorflow:Saving checkpoints for 10401 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5854.82, step = 10401\n",
      "INFO:tensorflow:global_step/sec: 55.9322\n",
      "INFO:tensorflow:loss = 5611.6, step = 10501 (1.772 sec)\n",
      "INFO:tensorflow:global_step/sec: 51.7345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 5317.19, step = 10601 (1.933 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.582\n",
      "INFO:tensorflow:loss = 5592.86, step = 10701 (2.032 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10800 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5405.13.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-11:57:30\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-10800\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-11:57:30\n",
      "INFO:tensorflow:Saving dict for global step 10800: average_loss = 10.7872, global_step = 10800, loss = 1078.72\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-10800\n",
      "INFO:tensorflow:Saving checkpoints for 10801 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5542.2, step = 10801\n",
      "INFO:tensorflow:global_step/sec: 63.8828\n",
      "INFO:tensorflow:loss = 5310.22, step = 10901 (1.565 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.4039\n",
      "INFO:tensorflow:loss = 5140.54, step = 11001 (1.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.5169\n",
      "INFO:tensorflow:loss = 5169.45, step = 11101 (1.498 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 11200 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5815.29.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-11:57:42\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-11200\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-11:57:43\n",
      "INFO:tensorflow:Saving dict for global step 11200: average_loss = 10.8269, global_step = 11200, loss = 1082.69\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-11200\n",
      "INFO:tensorflow:Saving checkpoints for 11201 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 4880.25, step = 11201\n",
      "INFO:tensorflow:global_step/sec: 63.7244\n",
      "INFO:tensorflow:loss = 5362.75, step = 11301 (1.569 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.0767\n",
      "INFO:tensorflow:loss = 5216.79, step = 11401 (1.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.2806\n",
      "INFO:tensorflow:loss = 5303.2, step = 11501 (1.449 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 11600 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5319.76.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-11:57:56\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-11600\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-11:57:57\n",
      "INFO:tensorflow:Saving dict for global step 11600: average_loss = 10.7808, global_step = 11600, loss = 1078.08\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-11600\n",
      "INFO:tensorflow:Saving checkpoints for 11601 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5215.5, step = 11601\n",
      "INFO:tensorflow:global_step/sec: 64.5713\n",
      "INFO:tensorflow:loss = 5088.93, step = 11701 (1.549 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.1739\n",
      "INFO:tensorflow:loss = 5445.42, step = 11801 (1.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.5497\n",
      "INFO:tensorflow:loss = 5532.75, step = 11901 (1.453 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12000 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5056.51.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-11:58:11\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-12000\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-11:58:11\n",
      "INFO:tensorflow:Saving dict for global step 12000: average_loss = 10.7158, global_step = 12000, loss = 1071.58\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-12000\n",
      "INFO:tensorflow:Saving checkpoints for 12001 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5633.79, step = 12001\n",
      "INFO:tensorflow:global_step/sec: 63.2739\n",
      "INFO:tensorflow:loss = 5203.25, step = 12101 (1.586 sec)\n",
      "INFO:tensorflow:global_step/sec: 60.9925\n",
      "INFO:tensorflow:loss = 4954.31, step = 12201 (1.650 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.6475\n",
      "INFO:tensorflow:loss = 5897.4, step = 12301 (1.719 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12400 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5548.06.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-11:58:26\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-12400\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-11:58:27\n",
      "INFO:tensorflow:Saving dict for global step 12400: average_loss = 10.7569, global_step = 12400, loss = 1075.69\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-12400\n",
      "INFO:tensorflow:Saving checkpoints for 12401 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5274.27, step = 12401\n",
      "INFO:tensorflow:global_step/sec: 53.8961\n",
      "INFO:tensorflow:loss = 5598.38, step = 12501 (1.855 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.7016\n",
      "INFO:tensorflow:loss = 5722.59, step = 12601 (1.719 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.922\n",
      "INFO:tensorflow:loss = 5084.18, step = 12701 (2.572 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12800 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5005.43.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-11:58:42\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-12800\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-11:58:43\n",
      "INFO:tensorflow:Saving dict for global step 12800: average_loss = 10.6956, global_step = 12800, loss = 1069.56\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-12800\n",
      "INFO:tensorflow:Saving checkpoints for 12801 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 6008.53, step = 12801\n",
      "INFO:tensorflow:global_step/sec: 63.5977\n",
      "INFO:tensorflow:loss = 5829.97, step = 12901 (1.572 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.5408\n",
      "INFO:tensorflow:loss = 5553.28, step = 13001 (1.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.5295\n",
      "INFO:tensorflow:loss = 6313.51, step = 13101 (1.481 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 13200 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5054.42.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-11:58:56\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-13200\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-11:58:56\n",
      "INFO:tensorflow:Saving dict for global step 13200: average_loss = 10.8, global_step = 13200, loss = 1080.0\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-13200\n",
      "INFO:tensorflow:Saving checkpoints for 13201 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5162.28, step = 13201\n",
      "INFO:tensorflow:global_step/sec: 65.6291\n",
      "INFO:tensorflow:loss = 5872.55, step = 13301 (1.524 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.3588\n",
      "INFO:tensorflow:loss = 5766.2, step = 13401 (1.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.952\n",
      "INFO:tensorflow:loss = 4818.68, step = 13501 (1.472 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 13600 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5684.44.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-11:59:10\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-13600\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-11:59:11\n",
      "INFO:tensorflow:Saving dict for global step 13600: average_loss = 10.678, global_step = 13600, loss = 1067.8\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-13600\n",
      "INFO:tensorflow:Saving checkpoints for 13601 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5246.16, step = 13601\n",
      "INFO:tensorflow:global_step/sec: 55.9835\n",
      "INFO:tensorflow:loss = 5170.69, step = 13701 (1.771 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.8839\n",
      "INFO:tensorflow:loss = 5910.68, step = 13801 (1.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.2568\n",
      "INFO:tensorflow:loss = 5716.97, step = 13901 (1.481 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 14000 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5157.14.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-11:59:23\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-14000\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-11:59:24\n",
      "INFO:tensorflow:Saving dict for global step 14000: average_loss = 10.6732, global_step = 14000, loss = 1067.32\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-14000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 14001 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5122.63, step = 14001\n",
      "INFO:tensorflow:global_step/sec: 64.5367\n",
      "INFO:tensorflow:loss = 4993.39, step = 14101 (1.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.6117\n",
      "INFO:tensorflow:loss = 5426.38, step = 14201 (1.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.675\n",
      "INFO:tensorflow:loss = 5532.45, step = 14301 (1.456 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 14400 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4950.8.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-11:59:36\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-14400\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-11:59:36\n",
      "INFO:tensorflow:Saving dict for global step 14400: average_loss = 10.6853, global_step = 14400, loss = 1068.53\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-14400\n",
      "INFO:tensorflow:Saving checkpoints for 14401 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5223.81, step = 14401\n",
      "INFO:tensorflow:global_step/sec: 64.9531\n",
      "INFO:tensorflow:loss = 4484.08, step = 14501 (1.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.0055\n",
      "INFO:tensorflow:loss = 5543.67, step = 14601 (1.434 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.5662\n",
      "INFO:tensorflow:loss = 5007.44, step = 14701 (1.502 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 14800 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5081.86.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-11:59:48\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-14800\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-11:59:49\n",
      "INFO:tensorflow:Saving dict for global step 14800: average_loss = 10.6586, global_step = 14800, loss = 1065.86\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-14800\n",
      "INFO:tensorflow:Saving checkpoints for 14801 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5356.95, step = 14801\n",
      "INFO:tensorflow:global_step/sec: 65.6278\n",
      "INFO:tensorflow:loss = 5656.91, step = 14901 (1.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.2378\n",
      "INFO:tensorflow:loss = 5340.02, step = 15001 (1.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.6294\n",
      "INFO:tensorflow:loss = 5548.56, step = 15101 (1.457 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 15200 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5383.12.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:00:01\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-15200\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:00:02\n",
      "INFO:tensorflow:Saving dict for global step 15200: average_loss = 10.8317, global_step = 15200, loss = 1083.17\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-15200\n",
      "INFO:tensorflow:Saving checkpoints for 15201 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5022.98, step = 15201\n",
      "INFO:tensorflow:global_step/sec: 64.9349\n",
      "INFO:tensorflow:loss = 5052.22, step = 15301 (1.536 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.5295\n",
      "INFO:tensorflow:loss = 5215.43, step = 15401 (1.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.6012\n",
      "INFO:tensorflow:loss = 5144.86, step = 15501 (1.572 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 15600 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4915.83.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:00:14\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-15600\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:00:15\n",
      "INFO:tensorflow:Saving dict for global step 15600: average_loss = 10.6569, global_step = 15600, loss = 1065.69\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-15600\n",
      "INFO:tensorflow:Saving checkpoints for 15601 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5877.03, step = 15601\n",
      "INFO:tensorflow:global_step/sec: 64.9393\n",
      "INFO:tensorflow:loss = 4827.19, step = 15701 (1.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.5847\n",
      "INFO:tensorflow:loss = 4875.47, step = 15801 (1.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.558\n",
      "INFO:tensorflow:loss = 5179.5, step = 15901 (1.502 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 16000 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4686.02.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:00:29\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-16000\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:00:30\n",
      "INFO:tensorflow:Saving dict for global step 16000: average_loss = 10.6488, global_step = 16000, loss = 1064.88\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-16000\n",
      "INFO:tensorflow:Saving checkpoints for 16001 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5048.58, step = 16001\n",
      "INFO:tensorflow:global_step/sec: 35.6835\n",
      "INFO:tensorflow:loss = 4711.87, step = 16101 (2.803 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.1311\n",
      "INFO:tensorflow:loss = 4892.06, step = 16201 (1.750 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.169\n",
      "INFO:tensorflow:loss = 5382.83, step = 16301 (1.534 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 16400 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6049.81.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:00:46\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-16400\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:00:47\n",
      "INFO:tensorflow:Saving dict for global step 16400: average_loss = 10.7692, global_step = 16400, loss = 1076.92\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-16400\n",
      "INFO:tensorflow:Saving checkpoints for 16401 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5837.38, step = 16401\n",
      "INFO:tensorflow:global_step/sec: 59.9587\n",
      "INFO:tensorflow:loss = 5329.54, step = 16501 (1.673 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.3372\n",
      "INFO:tensorflow:loss = 5457.59, step = 16601 (1.851 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.6125\n",
      "INFO:tensorflow:loss = 4623.17, step = 16701 (1.720 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 16800 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5570.82.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:01:01\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-16800\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:01:02\n",
      "INFO:tensorflow:Saving dict for global step 16800: average_loss = 10.6716, global_step = 16800, loss = 1067.16\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-16800\n",
      "INFO:tensorflow:Saving checkpoints for 16801 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 4945.1, step = 16801\n",
      "INFO:tensorflow:global_step/sec: 62.3836\n",
      "INFO:tensorflow:loss = 4890.54, step = 16901 (1.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.8946\n",
      "INFO:tensorflow:loss = 5280.82, step = 17001 (1.571 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.5746\n",
      "INFO:tensorflow:loss = 4998.46, step = 17101 (1.519 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 17200 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5432.5.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:01:14\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-17200\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:01:15\n",
      "INFO:tensorflow:Saving dict for global step 17200: average_loss = 10.6298, global_step = 17200, loss = 1062.98\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-17200\n",
      "INFO:tensorflow:Saving checkpoints for 17201 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 4912.37, step = 17201\n",
      "INFO:tensorflow:global_step/sec: 62.428\n",
      "INFO:tensorflow:loss = 5231.15, step = 17301 (1.602 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.8745\n",
      "INFO:tensorflow:loss = 5350.04, step = 17401 (1.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.5263\n",
      "INFO:tensorflow:loss = 5469.3, step = 17501 (1.504 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 17600 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5051.02.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:01:27\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-17600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:01:28\n",
      "INFO:tensorflow:Saving dict for global step 17600: average_loss = 10.6173, global_step = 17600, loss = 1061.73\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-17600\n",
      "INFO:tensorflow:Saving checkpoints for 17601 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5613.62, step = 17601\n",
      "INFO:tensorflow:global_step/sec: 64.3762\n",
      "INFO:tensorflow:loss = 5036.18, step = 17701 (1.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.6289\n",
      "INFO:tensorflow:loss = 6015.16, step = 17801 (1.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.2984\n",
      "INFO:tensorflow:loss = 5357.61, step = 17901 (1.502 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 18000 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5434.82.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:01:40\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-18000\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:01:41\n",
      "INFO:tensorflow:Saving dict for global step 18000: average_loss = 10.6963, global_step = 18000, loss = 1069.63\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-18000\n",
      "INFO:tensorflow:Saving checkpoints for 18001 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5330.99, step = 18001\n",
      "INFO:tensorflow:global_step/sec: 64.2854\n",
      "INFO:tensorflow:loss = 4611.5, step = 18101 (1.618 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.4249\n",
      "INFO:tensorflow:loss = 4734.21, step = 18201 (1.757 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.7716\n",
      "INFO:tensorflow:loss = 5187.02, step = 18301 (1.603 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 18400 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4963.18.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:01:55\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-18400\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:01:55\n",
      "INFO:tensorflow:Saving dict for global step 18400: average_loss = 10.702, global_step = 18400, loss = 1070.2\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-18400\n",
      "INFO:tensorflow:Saving checkpoints for 18401 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5364.28, step = 18401\n",
      "INFO:tensorflow:global_step/sec: 47.2288\n",
      "INFO:tensorflow:loss = 4801.79, step = 18501 (2.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.46\n",
      "INFO:tensorflow:loss = 5416.7, step = 18601 (1.771 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.8981\n",
      "INFO:tensorflow:loss = 5187.37, step = 18701 (2.061 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 18800 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5187.01.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:02:11\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-18800\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:02:11\n",
      "INFO:tensorflow:Saving dict for global step 18800: average_loss = 10.7958, global_step = 18800, loss = 1079.58\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-18800\n",
      "INFO:tensorflow:Saving checkpoints for 18801 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5174.73, step = 18801\n",
      "INFO:tensorflow:global_step/sec: 64.6146\n",
      "INFO:tensorflow:loss = 5206.96, step = 18901 (1.548 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.9467\n",
      "INFO:tensorflow:loss = 4970.08, step = 19001 (1.487 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.3769\n",
      "INFO:tensorflow:loss = 4993.46, step = 19101 (1.469 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 19200 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4770.16.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:02:23\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-19200\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:02:24\n",
      "INFO:tensorflow:Saving dict for global step 19200: average_loss = 10.6229, global_step = 19200, loss = 1062.29\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-19200\n",
      "INFO:tensorflow:Saving checkpoints for 19201 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5181.73, step = 19201\n",
      "INFO:tensorflow:global_step/sec: 64.7391\n",
      "INFO:tensorflow:loss = 4633.43, step = 19301 (1.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.8991\n",
      "INFO:tensorflow:loss = 5023.93, step = 19401 (1.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.2111\n",
      "INFO:tensorflow:loss = 5519.6, step = 19501 (1.518 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 19600 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5083.97.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:02:38\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-19600\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:02:39\n",
      "INFO:tensorflow:Saving dict for global step 19600: average_loss = 10.6036, global_step = 19600, loss = 1060.36\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-19600\n",
      "INFO:tensorflow:Saving checkpoints for 19601 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5471.2, step = 19601\n",
      "INFO:tensorflow:global_step/sec: 64.5793\n",
      "INFO:tensorflow:loss = 4734.8, step = 19701 (1.533 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.0378\n",
      "INFO:tensorflow:loss = 5202.91, step = 19801 (1.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.0261\n",
      "INFO:tensorflow:loss = 5121.33, step = 19901 (1.486 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4795.93.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:02:54\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-20000\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:02:54\n",
      "INFO:tensorflow:Saving dict for global step 20000: average_loss = 10.7117, global_step = 20000, loss = 1071.17\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-20000\n",
      "INFO:tensorflow:Saving checkpoints for 20001 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5337.94, step = 20001\n",
      "INFO:tensorflow:global_step/sec: 64.2719\n",
      "INFO:tensorflow:loss = 5485.23, step = 20101 (1.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.4954\n",
      "INFO:tensorflow:loss = 5374.2, step = 20201 (1.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.9105\n",
      "INFO:tensorflow:loss = 5179.87, step = 20301 (1.453 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20400 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5810.82.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:03:06\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-20400\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:03:07\n",
      "INFO:tensorflow:Saving dict for global step 20400: average_loss = 10.5861, global_step = 20400, loss = 1058.61\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-20400\n",
      "INFO:tensorflow:Saving checkpoints for 20401 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5594.82, step = 20401\n",
      "INFO:tensorflow:global_step/sec: 63.6478\n",
      "INFO:tensorflow:loss = 4874.63, step = 20501 (1.572 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.2091\n",
      "INFO:tensorflow:loss = 4979.39, step = 20601 (1.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.1644\n",
      "INFO:tensorflow:loss = 5045.67, step = 20701 (2.105 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20800 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5030.96.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:03:20\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-20800\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:03:21\n",
      "INFO:tensorflow:Saving dict for global step 20800: average_loss = 10.5914, global_step = 20800, loss = 1059.14\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-20800\n",
      "INFO:tensorflow:Saving checkpoints for 20801 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5056.41, step = 20801\n",
      "INFO:tensorflow:global_step/sec: 63.4284\n",
      "INFO:tensorflow:loss = 5426.95, step = 20901 (1.565 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.7774\n",
      "INFO:tensorflow:loss = 4959.03, step = 21001 (1.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.8237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 4794.91, step = 21101 (1.456 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 21200 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5437.81.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:03:33\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-21200\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:03:34\n",
      "INFO:tensorflow:Saving dict for global step 21200: average_loss = 10.5768, global_step = 21200, loss = 1057.68\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-21200\n",
      "INFO:tensorflow:Saving checkpoints for 21201 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 4799.99, step = 21201\n",
      "INFO:tensorflow:global_step/sec: 63.8038\n",
      "INFO:tensorflow:loss = 5081.23, step = 21301 (1.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.0711\n",
      "INFO:tensorflow:loss = 5256.62, step = 21401 (1.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.0017\n",
      "INFO:tensorflow:loss = 5032.09, step = 21501 (1.471 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 21600 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5230.64.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:03:46\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-21600\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:03:46\n",
      "INFO:tensorflow:Saving dict for global step 21600: average_loss = 10.5737, global_step = 21600, loss = 1057.37\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-21600\n",
      "INFO:tensorflow:Saving checkpoints for 21601 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5342.89, step = 21601\n",
      "INFO:tensorflow:global_step/sec: 66.2102\n",
      "INFO:tensorflow:loss = 4894.24, step = 21701 (1.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.5539\n",
      "INFO:tensorflow:loss = 5321.86, step = 21801 (1.487 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.5973\n",
      "INFO:tensorflow:loss = 4935.38, step = 21901 (1.479 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 22000 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5119.63.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:03:58\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-22000\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:03:59\n",
      "INFO:tensorflow:Saving dict for global step 22000: average_loss = 10.5854, global_step = 22000, loss = 1058.54\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-22000\n",
      "INFO:tensorflow:Saving checkpoints for 22001 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5370.37, step = 22001\n",
      "INFO:tensorflow:global_step/sec: 64.5458\n",
      "INFO:tensorflow:loss = 5846.78, step = 22101 (1.549 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.9639\n",
      "INFO:tensorflow:loss = 4927.07, step = 22201 (1.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.0915\n",
      "INFO:tensorflow:loss = 4572.19, step = 22301 (1.447 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 22400 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5483.23.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:04:11\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-22400\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:04:12\n",
      "INFO:tensorflow:Saving dict for global step 22400: average_loss = 10.5903, global_step = 22400, loss = 1059.03\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-22400\n",
      "INFO:tensorflow:Saving checkpoints for 22401 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 4904.24, step = 22401\n",
      "INFO:tensorflow:global_step/sec: 65.8672\n",
      "INFO:tensorflow:loss = 5371.78, step = 22501 (1.518 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.9946\n",
      "INFO:tensorflow:loss = 4684.45, step = 22601 (1.539 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.0887\n",
      "INFO:tensorflow:loss = 5153.43, step = 22701 (1.551 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 22800 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5943.24.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:04:24\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-22800\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:04:25\n",
      "INFO:tensorflow:Saving dict for global step 22800: average_loss = 10.6468, global_step = 22800, loss = 1064.68\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-22800\n",
      "INFO:tensorflow:Saving checkpoints for 22801 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5194.78, step = 22801\n",
      "INFO:tensorflow:global_step/sec: 60.3285\n",
      "INFO:tensorflow:loss = 5118.54, step = 22901 (1.658 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.1065\n",
      "INFO:tensorflow:loss = 5078.34, step = 23001 (1.782 sec)\n",
      "INFO:tensorflow:global_step/sec: 52.5012\n",
      "INFO:tensorflow:loss = 5732.08, step = 23101 (1.924 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 23200 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5365.5.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:04:39\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-23200\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:04:39\n",
      "INFO:tensorflow:Saving dict for global step 23200: average_loss = 10.5871, global_step = 23200, loss = 1058.71\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-23200\n",
      "INFO:tensorflow:Saving checkpoints for 23201 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5065.68, step = 23201\n",
      "INFO:tensorflow:global_step/sec: 63.0039\n",
      "INFO:tensorflow:loss = 5015.87, step = 23301 (1.585 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.5034\n",
      "INFO:tensorflow:loss = 5071.43, step = 23401 (1.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.6079\n",
      "INFO:tensorflow:loss = 4837.22, step = 23501 (1.525 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 23600 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5400.04.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:04:52\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-23600\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:04:53\n",
      "INFO:tensorflow:Saving dict for global step 23600: average_loss = 10.6682, global_step = 23600, loss = 1066.82\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-23600\n",
      "INFO:tensorflow:Saving checkpoints for 23601 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5157.67, step = 23601\n",
      "INFO:tensorflow:global_step/sec: 63.6466\n",
      "INFO:tensorflow:loss = 5233.98, step = 23701 (1.571 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.0595\n",
      "INFO:tensorflow:loss = 4740.88, step = 23801 (1.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.5591\n",
      "INFO:tensorflow:loss = 4935.82, step = 23901 (1.484 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 24000 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4998.47.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:05:05\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-24000\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:05:06\n",
      "INFO:tensorflow:Saving dict for global step 24000: average_loss = 10.6821, global_step = 24000, loss = 1068.21\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-24000\n",
      "INFO:tensorflow:Saving checkpoints for 24001 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 4848.34, step = 24001\n",
      "INFO:tensorflow:global_step/sec: 64.2795\n",
      "INFO:tensorflow:loss = 5215.53, step = 24101 (1.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.5919\n",
      "INFO:tensorflow:loss = 5555.66, step = 24201 (1.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.7924\n",
      "INFO:tensorflow:loss = 5715.1, step = 24301 (1.469 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 24400 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4812.18.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:05:18\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-24400\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:05:18\n",
      "INFO:tensorflow:Saving dict for global step 24400: average_loss = 10.7928, global_step = 24400, loss = 1079.28\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-24400\n",
      "INFO:tensorflow:Saving checkpoints for 24401 into tf_wx_model\\model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 5676.93, step = 24401\n",
      "INFO:tensorflow:global_step/sec: 53.8843\n",
      "INFO:tensorflow:loss = 4942.11, step = 24501 (1.856 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.8822\n",
      "INFO:tensorflow:loss = 5290.45, step = 24601 (1.518 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.2147\n",
      "INFO:tensorflow:loss = 5103.21, step = 24701 (1.503 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 24800 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5012.48.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:05:31\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-24800\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:05:31\n",
      "INFO:tensorflow:Saving dict for global step 24800: average_loss = 10.5444, global_step = 24800, loss = 1054.44\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-24800\n",
      "INFO:tensorflow:Saving checkpoints for 24801 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5112.87, step = 24801\n",
      "INFO:tensorflow:global_step/sec: 63.6057\n",
      "INFO:tensorflow:loss = 4404.61, step = 24901 (1.588 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.2681\n",
      "INFO:tensorflow:loss = 5007.54, step = 25001 (1.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.695\n",
      "INFO:tensorflow:loss = 5060.42, step = 25101 (1.439 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 25200 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5069.97.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:05:44\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-25200\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:05:45\n",
      "INFO:tensorflow:Saving dict for global step 25200: average_loss = 10.5475, global_step = 25200, loss = 1054.75\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-25200\n",
      "INFO:tensorflow:Saving checkpoints for 25201 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5722.75, step = 25201\n",
      "INFO:tensorflow:global_step/sec: 63.2608\n",
      "INFO:tensorflow:loss = 5114.43, step = 25301 (1.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.8485\n",
      "INFO:tensorflow:loss = 5984.35, step = 25401 (1.524 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.859\n",
      "INFO:tensorflow:loss = 5372.31, step = 25501 (1.833 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 25600 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5789.17.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:05:58\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-25600\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:05:59\n",
      "INFO:tensorflow:Saving dict for global step 25600: average_loss = 10.5326, global_step = 25600, loss = 1053.26\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-25600\n",
      "INFO:tensorflow:Saving checkpoints for 25601 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5644.64, step = 25601\n",
      "INFO:tensorflow:global_step/sec: 65.221\n",
      "INFO:tensorflow:loss = 5266.64, step = 25701 (1.549 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.0266\n",
      "INFO:tensorflow:loss = 5347.91, step = 25801 (1.454 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.3428\n",
      "INFO:tensorflow:loss = 5029.7, step = 25901 (1.482 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 26000 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4956.59.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:06:12\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-26000\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:06:13\n",
      "INFO:tensorflow:Saving dict for global step 26000: average_loss = 10.5613, global_step = 26000, loss = 1056.13\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-26000\n",
      "INFO:tensorflow:Saving checkpoints for 26001 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5600.66, step = 26001\n",
      "INFO:tensorflow:global_step/sec: 63.607\n",
      "INFO:tensorflow:loss = 5569.02, step = 26101 (1.572 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.1996\n",
      "INFO:tensorflow:loss = 5199.23, step = 26201 (1.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.8844\n",
      "INFO:tensorflow:loss = 5510.45, step = 26301 (1.464 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 26400 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4944.87.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:06:27\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-26400\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:06:28\n",
      "INFO:tensorflow:Saving dict for global step 26400: average_loss = 10.5412, global_step = 26400, loss = 1054.12\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-26400\n",
      "INFO:tensorflow:Saving checkpoints for 26401 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5090.18, step = 26401\n",
      "INFO:tensorflow:global_step/sec: 65.8118\n",
      "INFO:tensorflow:loss = 4662.91, step = 26501 (1.535 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.2572\n",
      "INFO:tensorflow:loss = 4758.72, step = 26601 (1.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.1641\n",
      "INFO:tensorflow:loss = 5664.01, step = 26701 (1.651 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 26800 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5018.46.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:06:40\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-26800\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:06:41\n",
      "INFO:tensorflow:Saving dict for global step 26800: average_loss = 10.6363, global_step = 26800, loss = 1063.63\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-26800\n",
      "INFO:tensorflow:Saving checkpoints for 26801 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5508.69, step = 26801\n",
      "INFO:tensorflow:global_step/sec: 53.865\n",
      "INFO:tensorflow:loss = 5181.0, step = 26901 (1.856 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.5912\n",
      "INFO:tensorflow:loss = 5820.24, step = 27001 (1.588 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.4049\n",
      "INFO:tensorflow:loss = 5029.56, step = 27101 (1.543 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 27200 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5564.09.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:06:56\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-27200\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:06:57\n",
      "INFO:tensorflow:Saving dict for global step 27200: average_loss = 10.5185, global_step = 27200, loss = 1051.85\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-27200\n",
      "INFO:tensorflow:Saving checkpoints for 27201 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5122.85, step = 27201\n",
      "INFO:tensorflow:global_step/sec: 46.3512\n",
      "INFO:tensorflow:loss = 4448.48, step = 27301 (2.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.9012\n",
      "INFO:tensorflow:loss = 5313.82, step = 27401 (1.988 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.4183\n",
      "INFO:tensorflow:loss = 5117.24, step = 27501 (1.873 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 27600 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5440.88.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:07:11\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-27600\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:07:12\n",
      "INFO:tensorflow:Saving dict for global step 27600: average_loss = 10.5154, global_step = 27600, loss = 1051.54\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-27600\n",
      "INFO:tensorflow:Saving checkpoints for 27601 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5685.94, step = 27601\n",
      "INFO:tensorflow:global_step/sec: 38.6184\n",
      "INFO:tensorflow:loss = 5505.25, step = 27701 (2.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.8734\n",
      "INFO:tensorflow:loss = 4939.5, step = 27801 (2.609 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.2803\n",
      "INFO:tensorflow:loss = 5664.67, step = 27901 (1.465 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 28000 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5772.01.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:07:27\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-28000\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:07:28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 28000: average_loss = 10.5156, global_step = 28000, loss = 1051.56\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-28000\n",
      "INFO:tensorflow:Saving checkpoints for 28001 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5053.11, step = 28001\n",
      "INFO:tensorflow:global_step/sec: 65.1897\n",
      "INFO:tensorflow:loss = 5138.21, step = 28101 (1.518 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.7761\n",
      "INFO:tensorflow:loss = 5514.7, step = 28201 (1.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.2908\n",
      "INFO:tensorflow:loss = 5436.39, step = 28301 (1.449 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 28400 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5373.06.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:07:40\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-28400\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:07:40\n",
      "INFO:tensorflow:Saving dict for global step 28400: average_loss = 10.6816, global_step = 28400, loss = 1068.16\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-28400\n",
      "INFO:tensorflow:Saving checkpoints for 28401 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 4834.62, step = 28401\n",
      "INFO:tensorflow:global_step/sec: 65.1745\n",
      "INFO:tensorflow:loss = 5145.21, step = 28501 (1.535 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.2789\n",
      "INFO:tensorflow:loss = 5310.12, step = 28601 (1.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.752\n",
      "INFO:tensorflow:loss = 4885.8, step = 28701 (1.751 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 28800 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5736.84.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:07:53\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-28800\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:07:54\n",
      "INFO:tensorflow:Saving dict for global step 28800: average_loss = 10.5042, global_step = 28800, loss = 1050.42\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-28800\n",
      "INFO:tensorflow:Saving checkpoints for 28801 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 4887.97, step = 28801\n",
      "INFO:tensorflow:global_step/sec: 65.2224\n",
      "INFO:tensorflow:loss = 5904.43, step = 28901 (1.549 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.2418\n",
      "INFO:tensorflow:loss = 4740.25, step = 29001 (1.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.0385\n",
      "INFO:tensorflow:loss = 4700.21, step = 29101 (1.470 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 29200 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5130.55.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:08:06\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-29200\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:08:06\n",
      "INFO:tensorflow:Saving dict for global step 29200: average_loss = 10.547, global_step = 29200, loss = 1054.7\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-29200\n",
      "INFO:tensorflow:Saving checkpoints for 29201 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5016.23, step = 29201\n",
      "INFO:tensorflow:global_step/sec: 44.0492\n",
      "INFO:tensorflow:loss = 4619.76, step = 29301 (2.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.725\n",
      "INFO:tensorflow:loss = 5466.83, step = 29401 (2.050 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.826\n",
      "INFO:tensorflow:loss = 4913.86, step = 29501 (1.535 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 29600 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5307.69.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:08:21\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-29600\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:08:22\n",
      "INFO:tensorflow:Saving dict for global step 29600: average_loss = 10.5052, global_step = 29600, loss = 1050.52\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-29600\n",
      "INFO:tensorflow:Saving checkpoints for 29601 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5641.9, step = 29601\n",
      "INFO:tensorflow:global_step/sec: 63.8643\n",
      "INFO:tensorflow:loss = 5988.5, step = 29701 (1.566 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.2866\n",
      "INFO:tensorflow:loss = 5884.48, step = 29801 (1.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.7278\n",
      "INFO:tensorflow:loss = 5212.04, step = 29901 (1.455 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 30000 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5769.2.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:08:36\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-30000\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:08:37\n",
      "INFO:tensorflow:Saving dict for global step 30000: average_loss = 10.5339, global_step = 30000, loss = 1053.39\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-30000\n",
      "INFO:tensorflow:Saving checkpoints for 30001 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 4937.71, step = 30001\n",
      "INFO:tensorflow:global_step/sec: 49.5113\n",
      "INFO:tensorflow:loss = 4944.72, step = 30101 (2.029 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.7954\n",
      "INFO:tensorflow:loss = 4583.23, step = 30201 (1.816 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.838\n",
      "INFO:tensorflow:loss = 4804.09, step = 30301 (1.551 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 30400 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4614.38.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:08:51\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-30400\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:08:52\n",
      "INFO:tensorflow:Saving dict for global step 30400: average_loss = 10.5662, global_step = 30400, loss = 1056.62\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-30400\n",
      "INFO:tensorflow:Saving checkpoints for 30401 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5342.25, step = 30401\n",
      "INFO:tensorflow:global_step/sec: 57.6825\n",
      "INFO:tensorflow:loss = 4907.39, step = 30501 (1.734 sec)\n",
      "INFO:tensorflow:global_step/sec: 60.6124\n",
      "INFO:tensorflow:loss = 5426.27, step = 30601 (1.650 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.6799\n",
      "INFO:tensorflow:loss = 5467.41, step = 30701 (1.721 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 30800 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5479.7.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:09:05\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-30800\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:09:05\n",
      "INFO:tensorflow:Saving dict for global step 30800: average_loss = 10.4893, global_step = 30800, loss = 1048.93\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-30800\n",
      "INFO:tensorflow:Saving checkpoints for 30801 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5063.54, step = 30801\n",
      "INFO:tensorflow:global_step/sec: 53.6527\n",
      "INFO:tensorflow:loss = 5553.05, step = 30901 (1.848 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.9096\n",
      "INFO:tensorflow:loss = 5991.46, step = 31001 (1.855 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.8982\n",
      "INFO:tensorflow:loss = 5261.53, step = 31101 (2.586 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 31200 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5435.91.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:09:20\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-31200\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:09:20\n",
      "INFO:tensorflow:Saving dict for global step 31200: average_loss = 10.4924, global_step = 31200, loss = 1049.24\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-31200\n",
      "INFO:tensorflow:Saving checkpoints for 31201 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 4865.0, step = 31201\n",
      "INFO:tensorflow:global_step/sec: 63.6793\n",
      "INFO:tensorflow:loss = 4791.81, step = 31301 (1.554 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.2467\n",
      "INFO:tensorflow:loss = 5187.96, step = 31401 (1.487 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.9638\n",
      "INFO:tensorflow:loss = 4734.84, step = 31501 (1.487 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 31600 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5172.48.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:09:32\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-31600\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:09:33\n",
      "INFO:tensorflow:Saving dict for global step 31600: average_loss = 10.5272, global_step = 31600, loss = 1052.72\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-31600\n",
      "INFO:tensorflow:Saving checkpoints for 31601 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5125.44, step = 31601\n",
      "INFO:tensorflow:global_step/sec: 64.029\n",
      "INFO:tensorflow:loss = 5062.44, step = 31701 (1.562 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.3028\n",
      "INFO:tensorflow:loss = 5078.53, step = 31801 (1.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.1998\n",
      "INFO:tensorflow:loss = 4643.3, step = 31901 (1.723 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 32000 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4995.04.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:09:45\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-32000\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:09:46\n",
      "INFO:tensorflow:Saving dict for global step 32000: average_loss = 10.65, global_step = 32000, loss = 1065.0\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-32000\n",
      "INFO:tensorflow:Saving checkpoints for 32001 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 4925.9, step = 32001\n",
      "INFO:tensorflow:global_step/sec: 50.6864\n",
      "INFO:tensorflow:loss = 4663.97, step = 32101 (1.973 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.6279\n",
      "INFO:tensorflow:loss = 4750.83, step = 32201 (1.587 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.4857\n",
      "INFO:tensorflow:loss = 4853.88, step = 32301 (2.652 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 32400 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5500.8.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:10:02\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-32400\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:10:03\n",
      "INFO:tensorflow:Saving dict for global step 32400: average_loss = 10.4883, global_step = 32400, loss = 1048.83\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-32400\n",
      "INFO:tensorflow:Saving checkpoints for 32401 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5685.07, step = 32401\n",
      "INFO:tensorflow:global_step/sec: 63.1159\n",
      "INFO:tensorflow:loss = 5199.74, step = 32501 (1.598 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.2155\n",
      "INFO:tensorflow:loss = 5086.76, step = 32601 (1.487 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.8816\n",
      "INFO:tensorflow:loss = 4829.73, step = 32701 (1.521 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 32800 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5321.73.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:10:15\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-32800\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:10:16\n",
      "INFO:tensorflow:Saving dict for global step 32800: average_loss = 10.5407, global_step = 32800, loss = 1054.07\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-32800\n",
      "INFO:tensorflow:Saving checkpoints for 32801 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5606.64, step = 32801\n",
      "INFO:tensorflow:global_step/sec: 64.2486\n",
      "INFO:tensorflow:loss = 5144.15, step = 32901 (1.572 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.615\n",
      "INFO:tensorflow:loss = 4937.87, step = 33001 (1.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.9318\n",
      "INFO:tensorflow:loss = 5336.02, step = 33101 (1.564 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 33200 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4613.55.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:10:29\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-33200\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:10:30\n",
      "INFO:tensorflow:Saving dict for global step 33200: average_loss = 10.4716, global_step = 33200, loss = 1047.16\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-33200\n",
      "INFO:tensorflow:Saving checkpoints for 33201 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5275.27, step = 33201\n",
      "INFO:tensorflow:global_step/sec: 63.032\n",
      "INFO:tensorflow:loss = 4882.82, step = 33301 (1.571 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.5956\n",
      "INFO:tensorflow:loss = 5720.34, step = 33401 (1.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.5371\n",
      "INFO:tensorflow:loss = 5096.45, step = 33501 (1.549 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 33600 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5770.07.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:10:42\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-33600\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:10:43\n",
      "INFO:tensorflow:Saving dict for global step 33600: average_loss = 10.6076, global_step = 33600, loss = 1060.76\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-33600\n",
      "INFO:tensorflow:Saving checkpoints for 33601 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 4715.86, step = 33601\n",
      "INFO:tensorflow:global_step/sec: 63.609\n",
      "INFO:tensorflow:loss = 5626.5, step = 33701 (1.572 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.591\n",
      "INFO:tensorflow:loss = 5016.51, step = 33801 (1.548 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.3457\n",
      "INFO:tensorflow:loss = 5120.95, step = 33901 (1.485 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 34000 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4609.49.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:10:55\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-34000\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:10:56\n",
      "INFO:tensorflow:Saving dict for global step 34000: average_loss = 10.6199, global_step = 34000, loss = 1061.99\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-34000\n",
      "INFO:tensorflow:Saving checkpoints for 34001 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 4877.59, step = 34001\n",
      "INFO:tensorflow:global_step/sec: 56.1611\n",
      "INFO:tensorflow:loss = 4881.4, step = 34101 (1.781 sec)\n",
      "INFO:tensorflow:global_step/sec: 59.8068\n",
      "INFO:tensorflow:loss = 4862.71, step = 34201 (1.688 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.9426\n",
      "INFO:tensorflow:loss = 4855.02, step = 34301 (1.573 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 34400 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4936.89.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:11:10\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-34400\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:11:10\n",
      "INFO:tensorflow:Saving dict for global step 34400: average_loss = 10.4591, global_step = 34400, loss = 1045.91\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-34400\n",
      "INFO:tensorflow:Saving checkpoints for 34401 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5066.37, step = 34401\n",
      "INFO:tensorflow:global_step/sec: 64.2731\n",
      "INFO:tensorflow:loss = 5567.4, step = 34501 (1.537 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.9545\n",
      "INFO:tensorflow:loss = 4781.71, step = 34601 (1.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.5269\n",
      "INFO:tensorflow:loss = 4920.17, step = 34701 (1.481 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 34800 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5064.49.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:11:23\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-34800\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:11:23\n",
      "INFO:tensorflow:Saving dict for global step 34800: average_loss = 10.5702, global_step = 34800, loss = 1057.02\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-34800\n",
      "INFO:tensorflow:Saving checkpoints for 34801 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 4611.95, step = 34801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 65.7845\n",
      "INFO:tensorflow:loss = 4825.0, step = 34901 (1.535 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.0032\n",
      "INFO:tensorflow:loss = 5357.03, step = 35001 (1.449 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.9807\n",
      "INFO:tensorflow:loss = 5366.54, step = 35101 (1.523 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 35200 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5107.93.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:11:35\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-35200\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:11:36\n",
      "INFO:tensorflow:Saving dict for global step 35200: average_loss = 10.4711, global_step = 35200, loss = 1047.11\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-35200\n",
      "INFO:tensorflow:Saving checkpoints for 35201 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5630.94, step = 35201\n",
      "INFO:tensorflow:global_step/sec: 65.1469\n",
      "INFO:tensorflow:loss = 5898.39, step = 35301 (1.535 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.6836\n",
      "INFO:tensorflow:loss = 5411.6, step = 35401 (1.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.723\n",
      "INFO:tensorflow:loss = 4799.77, step = 35501 (1.450 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 35600 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5626.48.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:11:48\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-35600\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:11:49\n",
      "INFO:tensorflow:Saving dict for global step 35600: average_loss = 10.5798, global_step = 35600, loss = 1057.98\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-35600\n",
      "INFO:tensorflow:Saving checkpoints for 35601 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5538.63, step = 35601\n",
      "INFO:tensorflow:global_step/sec: 65.0842\n",
      "INFO:tensorflow:loss = 5150.34, step = 35701 (1.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.5418\n",
      "INFO:tensorflow:loss = 5156.32, step = 35801 (1.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.0497\n",
      "INFO:tensorflow:loss = 5563.93, step = 35901 (1.466 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 36000 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5508.2.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:12:01\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-36000\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:12:01\n",
      "INFO:tensorflow:Saving dict for global step 36000: average_loss = 10.7729, global_step = 36000, loss = 1077.29\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-36000\n",
      "INFO:tensorflow:Saving checkpoints for 36001 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 4886.44, step = 36001\n",
      "INFO:tensorflow:global_step/sec: 63.6232\n",
      "INFO:tensorflow:loss = 6012.35, step = 36101 (1.587 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.0053\n",
      "INFO:tensorflow:loss = 5001.06, step = 36201 (1.455 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.5601\n",
      "INFO:tensorflow:loss = 5264.52, step = 36301 (1.502 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 36400 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5397.95.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:12:14\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-36400\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:12:14\n",
      "INFO:tensorflow:Saving dict for global step 36400: average_loss = 10.6652, global_step = 36400, loss = 1066.52\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-36400\n",
      "INFO:tensorflow:Saving checkpoints for 36401 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5361.57, step = 36401\n",
      "INFO:tensorflow:global_step/sec: 64.3094\n",
      "INFO:tensorflow:loss = 5018.14, step = 36501 (1.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.9305\n",
      "INFO:tensorflow:loss = 5274.5, step = 36601 (1.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.2574\n",
      "INFO:tensorflow:loss = 5027.63, step = 36701 (1.465 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 36800 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4694.44.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:12:26\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-36800\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:12:27\n",
      "INFO:tensorflow:Saving dict for global step 36800: average_loss = 10.4978, global_step = 36800, loss = 1049.78\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-36800\n",
      "INFO:tensorflow:Saving checkpoints for 36801 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5357.15, step = 36801\n",
      "INFO:tensorflow:global_step/sec: 63.6501\n",
      "INFO:tensorflow:loss = 5052.93, step = 36901 (1.587 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.1982\n",
      "INFO:tensorflow:loss = 5649.62, step = 37001 (1.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.2596\n",
      "INFO:tensorflow:loss = 4859.44, step = 37101 (1.465 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 37200 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5383.55.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:12:39\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-37200\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:12:40\n",
      "INFO:tensorflow:Saving dict for global step 37200: average_loss = 10.4865, global_step = 37200, loss = 1048.65\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-37200\n",
      "INFO:tensorflow:Saving checkpoints for 37201 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5497.38, step = 37201\n",
      "INFO:tensorflow:global_step/sec: 59.1976\n",
      "INFO:tensorflow:loss = 5067.37, step = 37301 (1.689 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.9857\n",
      "INFO:tensorflow:loss = 5130.05, step = 37401 (1.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.2611\n",
      "INFO:tensorflow:loss = 4916.18, step = 37501 (1.481 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 37600 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5816.2.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:12:52\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-37600\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:12:53\n",
      "INFO:tensorflow:Saving dict for global step 37600: average_loss = 10.4426, global_step = 37600, loss = 1044.26\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-37600\n",
      "INFO:tensorflow:Saving checkpoints for 37601 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5083.9, step = 37601\n",
      "INFO:tensorflow:global_step/sec: 63.2574\n",
      "INFO:tensorflow:loss = 5604.93, step = 37701 (1.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.9061\n",
      "INFO:tensorflow:loss = 5517.41, step = 37801 (1.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.6582\n",
      "INFO:tensorflow:loss = 5234.1, step = 37901 (1.472 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 38000 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4972.98.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:13:05\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-38000\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:13:05\n",
      "INFO:tensorflow:Saving dict for global step 38000: average_loss = 10.5088, global_step = 38000, loss = 1050.88\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-38000\n",
      "INFO:tensorflow:Saving checkpoints for 38001 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5223.55, step = 38001\n",
      "INFO:tensorflow:global_step/sec: 62.9802\n",
      "INFO:tensorflow:loss = 5036.07, step = 38101 (1.572 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.5646\n",
      "INFO:tensorflow:loss = 4640.94, step = 38201 (1.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.6606\n",
      "INFO:tensorflow:loss = 5095.13, step = 38301 (1.472 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 38400 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4801.23.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:13:17\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-38400\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:13:18\n",
      "INFO:tensorflow:Saving dict for global step 38400: average_loss = 10.5551, global_step = 38400, loss = 1055.51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-38400\n",
      "INFO:tensorflow:Saving checkpoints for 38401 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5259.96, step = 38401\n",
      "INFO:tensorflow:global_step/sec: 64.5589\n",
      "INFO:tensorflow:loss = 4257.08, step = 38501 (1.567 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.0588\n",
      "INFO:tensorflow:loss = 5578.96, step = 38601 (1.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.3971\n",
      "INFO:tensorflow:loss = 5470.61, step = 38701 (1.541 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 38800 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5398.85.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:13:30\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-38800\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:13:31\n",
      "INFO:tensorflow:Saving dict for global step 38800: average_loss = 10.4451, global_step = 38800, loss = 1044.51\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-38800\n",
      "INFO:tensorflow:Saving checkpoints for 38801 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5804.57, step = 38801\n",
      "INFO:tensorflow:global_step/sec: 64.607\n",
      "INFO:tensorflow:loss = 5396.67, step = 38901 (1.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.0015\n",
      "INFO:tensorflow:loss = 4914.44, step = 39001 (1.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.3138\n",
      "INFO:tensorflow:loss = 5130.26, step = 39101 (1.486 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 39200 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5827.08.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:13:43\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-39200\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:13:43\n",
      "INFO:tensorflow:Saving dict for global step 39200: average_loss = 10.6649, global_step = 39200, loss = 1066.49\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-39200\n",
      "INFO:tensorflow:Saving checkpoints for 39201 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 4987.27, step = 39201\n",
      "INFO:tensorflow:global_step/sec: 60.0065\n",
      "INFO:tensorflow:loss = 5270.11, step = 39301 (1.672 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.5631\n",
      "INFO:tensorflow:loss = 5093.01, step = 39401 (1.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.3055\n",
      "INFO:tensorflow:loss = 5038.98, step = 39501 (1.532 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 39600 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4558.03.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:13:55\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-39600\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:13:56\n",
      "INFO:tensorflow:Saving dict for global step 39600: average_loss = 10.4977, global_step = 39600, loss = 1049.77\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-39600\n",
      "INFO:tensorflow:Saving checkpoints for 39601 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 4735.41, step = 39601\n",
      "INFO:tensorflow:global_step/sec: 64.9575\n",
      "INFO:tensorflow:loss = 5452.96, step = 39701 (1.535 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.1816\n",
      "INFO:tensorflow:loss = 5073.37, step = 39801 (1.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.5185\n",
      "INFO:tensorflow:loss = 4967.46, step = 39901 (1.486 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 40000 into tf_wx_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5024.61.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-09-12:14:08\n",
      "INFO:tensorflow:Restoring parameters from tf_wx_model\\model.ckpt-40000\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-12:14:09\n",
      "INFO:tensorflow:Saving dict for global step 40000: average_loss = 10.4366, global_step = 40000, loss = 1043.66\n"
     ]
    }
   ],
   "source": [
    "evaluations = []  \n",
    "STEPS = 400  \n",
    "for i in range(100):  \n",
    "    regressor.train(input_fn=wx_input_fn(X_train, y=y_train), steps=STEPS)\n",
    "    evaluations.append(regressor.evaluate(input_fn=wx_input_fn(X_val,\n",
    "                                                               y_val,\n",
    "                                                               num_epochs=1,\n",
    "                                                               shuffle=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA00AAAJQCAYAAABSPI/dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzs3X+8pVddH/rP10mAo6ADTWiZE2iCjdOLxjL0iPTmapEqE6iVMVoNtReuem9qC/2h7bSZ671ia30ldqr2WlGLbaBUDVBMhxS0IxoqLbcIEycwCToy/GiZGTShOIj1XEjCun/s5yRnhnPWmdnn7LP3Oef9fr32a569nmfvvfbaz5z9fPZaz3qqtRYAAABW9gXTrgAAAMAsE5oAAAA6hCYAAIAOoQkAAKBDaAIAAOgQmgAAADqEJgAAgA6hCQAAoENoAgAA6Lhs2hWYhCuuuKJdffXV064GAAAww+65555PtNauXGu7bRmarr766hw7dmza1QAAAGZYVf3Xi9nO8DwAAIAOoQkAAKBDaAIAAOgQmgAAADqEJgAAgA6hCQAAoENoAgAA6BCaAAAAOoQmAACADqEJAACgQ2gCAADoEJoAAAA6hCYAAIAOoQkAAKBDaAIAAOgQmgAAADqEJgAAgA6hCQAAoENoAgAA6BCaAAAAOi6bdgW2syPHz+Tw0ZM5e24xe3bP5eD+vTmwb37a1QIAAC6B0DQhR46fyaE7T2TxoUeSJGfOLebQnSeSRHACAIAtxPC8CTl89OSjgWnJ4kOP5PDRk1OqEQAAMA6haULOnlu8pHIAAGA2CU0Tsmf33CWVAwAAs0lompCD+/dm7vJd55XNXb4rB/fvnVKNAACAcZgIYkKWJnswex4AAGxtQtMEHdg3LyQBAMAWZ3geAABAh9AEAADQITQBAAB0CE0AAAAdQhMAAEDHxEJTVd1eVQ9U1X3Lyt5YVfcOt49W1b3L1h2qqlNVdbKq9i8rv2EoO1VVt0yqvgAAACuZ5JTjr0vyk0lev1TQWvv2peWq+tEknxqWn5XkpiRfnmRPkl+tqi8bNn11km9IcjrJe6vqrtbaByZYbwAAgEdNLDS11t5ZVVevtK6qKsm3JXnBUPSSJG9orX0myUeq6lSS5w7rTrXWPjw87g3DtkITAACwKaZ1TtPXJPm91toHh/vzST62bP3poWy1cgAAgE0xrdD00iR3LLtfK2zTOuWfp6purqpjVXXswQcf3IAqAgAATCE0VdVlSW5M8sZlxaeTPH3Z/auSnO2Uf57W2mtaawuttYUrr7xyYysNAADsWNPoafr6JL/dWju9rOyuJDdV1eOr6pok1yZ5T5L3Jrm2qq6pqsdlNFnEXZteYwAAYMea5JTjdyT5L0n2VtXpqvruYdVNOX9oXlpr9yd5U0YTPPyHJK9orT3SWns4ySuTHE3yW0neNGwLAACwKaq1FU8R2tIWFhbasWPHpl0NAABghlXVPa21hbW2m9ZEEAAAAFuC0AQAANAhNAEAAHQITQAAAB1CEwAAQIfQBAAA0CE0AQAAdAhNAAAAHUITAABAh9AEAADQITQBAAB0CE0AAAAdQhMAAECH0AQAANAhNAEAAHQITQAAAB1CEwAAQIfQBAAA0CE0AQAAdAhNAAAAHUITAABAh9AEAADQITQBAAB0CE0AAAAdQhMAAECH0AQAANAhNAEAAHQITQAAAB1CEwAAQIfQBAAA0CE0AQAAdAhNAAAAHUITAABAh9AEAADQITQBAAB0CE0AAAAdQhMAAECH0AQAANAhNAEAAHQITQAAAB1CEwAAQIfQBAAA0CE0AQAAdAhNAAAAHUITAABAh9AEAADQITQBAAB0CE0AAAAdQhMAAECH0AQAANAhNAEAAHQITQAAAB1CEwAAQIfQBAAA0CE0AQAAdAhNAAAAHUITAABAh9AEAADQITQBAAB0CE0AAAAdQhMAAECH0AQAANAhNAEAAHQITQAAAB0TC01VdXtVPVBV911Q/jer6mRV3V9V/2RZ+aGqOjWs27+s/Iah7FRV3TKp+gIAAKzksgk+9+uS/GSS1y8VVNXXJXlJkq9srX2mqp46lD8ryU1JvjzJniS/WlVfNjzs1Um+IcnpJO+tqrtaax+YYL0BAAAeNbHQ1Fp7Z1VdfUHxX09yW2vtM8M2DwzlL0nyhqH8I1V1Kslzh3WnWmsfTpKqesOwrdAEAABsis0+p+nLknxNVf1GVf16VX3VUD6f5GPLtjs9lK1WDgAAsCkmOTxvtdd7cpLnJfmqJG+qqmcmqRW2bVk51LWVnriqbk5yc5I84xnP2JDKAgAAbHZP0+kkd7aR9yT5XJIrhvKnL9vuqiRnO+Wfp7X2mtbaQmtt4corr5xI5QEAgJ1ns0PTkSQvSJJhoofHJflEkruS3FRVj6+qa5Jcm+Q9Sd6b5NqquqaqHpfRZBF3bXKdAQCAHWxiw/Oq6o4kz09yRVWdTvKqJLcnuX2YhvyzSV7eWmtJ7q+qN2U0wcPDSV7RWntkeJ5XJjmaZFeS21tr90+qzgAAABeqUWbZXhYWFtqxY8emXQ0AAGCGVdU9rbWFtbbb7OF5AAAAW4rQBAAA0CE0AQAAdAhNAAAAHUITAABAh9AEAADQITQBAAB0CE0AAAAdQhMAAECH0AQAANAhNAEAAHQITQAAAB1CEwAAQIfQBAAA0CE0AQAAdAhNAAAAHUITAABAh9AEAADQITQBAAB0CE0AAAAdQhMAAECH0AQAANAhNAEAAHQITQAAAB1CEwAAQIfQBAAA0CE0AQAAdAhNAAAAHUITAABAh9AEAADQITQBAAB0CE0AAAAdQhMAAECH0AQAANAhNAEAAHQITQAAAB1CEwAAQIfQBAAA0CE0AQAAdAhNAAAAHUITAABAh9AEAADQITQBAAB0CE0AAAAdQhMAAECH0AQAANAhNAEAAHQITQAAAB1CEwAAQIfQBAAA0CE0AQAAdAhNAAAAHUITAABAh9AEAADQITQBAAB0CE0AAAAdQhMAAECH0AQAANAhNAEAAHQITQAAAB1CEwAAQIfQBAAA0CE0AQAAdAhNAAAAHUITAABAx8RCU1XdXlUPVNV9y8p+sKrOVNW9w+3Fy9YdqqpTVXWyqvYvK79hKDtVVbdMqr4AAAArmWRP0+uS3LBC+Y+31p493H4pSarqWUluSvLlw2N+qqp2VdWuJK9O8qIkz0ry0mFbAACATXHZpJ64tfbOqrr6Ijd/SZI3tNY+k+QjVXUqyXOHdadaax9Okqp6w7DtBza4ugAAACuaxjlNr6yq9w/D9548lM0n+diybU4PZauVf56qurmqjlXVsQcffHAS9QYAAHagzQ5NP53kS5M8O8nHk/zoUF4rbNs65Z9f2NprWmsLrbWFK6+8ciPqCgAAMLnheStprf3e0nJV/WyStw53Tyd5+rJNr0pydlherRwAAGDiNrWnqaqetuzuNydZmlnvriQ3VdXjq+qaJNcmeU+S9ya5tqquqarHZTRZxF2bWWcAAGBnm1hPU1XdkeT5Sa6oqtNJXpXk+VX17IyG2H00yV9Lktba/VX1powmeHg4yStaa48Mz/PKJEeT7Epye2vt/knVGQAA4ELV2oqnCG1pCwsL7dixY9OuBgAAMMOq6p7W2sJa223qOU085sjxMzl89GTOnlvMnt1zObh/bw7sW3FiQAAAYIqEpik4cvxMDt15IosPPZIkOXNuMYfuPJEkghMAAMyYaVynacc7fPTko4FpyeJDj+Tw0ZNTqhEAALAaoWkKzp5bvKRyAABgeoSmKdize+6SygEAgOkRmqbg4P69mbt813llc5fvysH9e6dUIwAAYDUmgpiCpckezJ4HAACzT2iakgP75oUkAADYAgzPAwAA6BCaAAAAOoQmAACADqEJAACgQ2gCAADoEJoAAAA6hCYAAIAOoQkAAKBDaAIAAOgQmgAAADqEJgAAgA6hCQAAoENoAgAA6BCaAAAAOoQmAACADqEJAACgQ2gCAADoEJoAAAA6hCYAAIAOoQkAAKBDaAIAAOgQmgAAADqEJgAAgA6hCQAAoENoAgAA6BCaAAAAOoQmAACADqEJAACgQ2gCAADoEJoAAAA6hCYAAIAOoQkAAKBDaAIAAOgQmgAAADqEJgAAgA6hCQAAoENoAgAA6BCaAAAAOoQmAACADqEJAACgQ2gCAADoEJoAAAA6hCYAAIAOoQkAAKBDaAIAAOgQmgAAADqEJgAAgA6hCQAAoENoAgAA6LhsrQ2q6qokNyX5miR7kiwmuS/J25L8cmvtcxOtIQAAwBR1Q1NVvTbJfJK3JvmRJA8keUKSL0tyQ5Lvr6pbWmvvnHRFAQAApmGtnqYfba3dt0L5fUnurKrHJXnGxlcLAABgNqx1TtN/W21FVT2jtfbZ1tqpDa4TAADAzFgrNP3HpYWq+rUL1h3Z8NoAAADMmLVCUy1bfkpnHQAAwLa0VmhqqyyvdB8AAGDbWSs0PbWqvq+q/u6y5aX7V/YeWFW3V9UDVfV5E0lU1d+rqlZVVwz3q6p+oqpOVdX7q+o5y7Z9eVV9cLi9fIz3CAAAMLa1QtPPJnlSkicuW166/y/XeOzrMpqW/DxV9fQk35DzJ5l4UZJrh9vNSX562PYpSV6V5KuTPDfJq6rqyWu8LgAAwIbpTjneWvuH4z5xa+2dVXX1Cqt+PMnfT/KWZWUvSfL61lpL8u6q2l1VT0vy/CRvb619Mkmq6u0ZBbE7xq0XAADApej2NFXV/1FV1w7LNQy5+9QwhG7fpb5YVX1TkjOttfddsGo+yceW3T89lK1WvtJz31xVx6rq2IMPPnipVQMAAFjRWsPz/naSjw7LL03yZ5I8M8n3JfmJS3mhqvrCJN+f5AdWWr1CWeuUf35ha69prS201hauvLJ7uhUAAMBFWys0Pdxae2hY/saMhtD999baryb5okt8rS9Nck2S91XVR5NcleQ3q+pPZNSD9PRl216V5GynHAAAYFOsFZo+V1VPq6onJPkLSX512bq5S3mh1tqJ1tpTW2tXt9auzigQPae19rtJ7krysmEI4POSfKq19vEkR5O8sKqePEwA8cKhDAAAYFN0J4LIaCjdsSS7ktzVWrs/Sarqzyf5cO+BVXVHRhM5XFFVp5O8qrX2r1bZ/JeSvDjJqSR/lOQ7k6S19smq+qEk7x22+0dLk0IAAABshhpNWNfZoOqyJE9qrf3+srIvTPIFrbU/nHD9xrKwsNCOHTs27WoAAAAzrKruaa0trLXdWrPnfVWSK5YCU1W9rKrekuS2JI/bkJoCAADMsLXOafoXST6bJFX1tRmFpdcn+VSS10y2agAAANO31jlNu5adQ/TtSV7TWvvFJL9YVfdOtmoAAADTt1ZP067hnKZkNHve3cvWrRW4AAAAtry1gs8dSX69qj6RZDHJf0qSqvpTGQ3RAwAA2Na6oam19sNV9WtJnpbkV9pjU+19QZK/OenKAQAATFs3NFXVE1tr776wvLX2OxdsM5NTjwMAAKzXWsPz3jJM+PCWJPe01v5HklTVM5N8XZJvS/KzSd480VruMEeOn8nhoydz9txi9uyey8H9e3Ng3/y0qwUAADvSWsPz/kJVvTjJX0tyfVU9OcnDSU4meVuSl7fWfnfy1dw5jhw/k0N3nsjiQ48kSc6cW8yhO08kieAEAABTsOYMeK21X0ryS5tQF5IcPnry0cC0ZPGhR3L46EmhCQAApmCtKcfZZGfPLV5SOQAAMFlC04zZs3vuksoBAIDJEppmzMH9ezN3+a7zyuYu35WD+/dOqUYAALCzXVRoqqovrarHD8vPr6q/VVW7J1u1nenAvvnceuN1md89l0oyv3sut954nfOZAABgSuqx69V2NhpNO76Q5OokR5PclWRva+3FE63dmBYWFtqxY8emXQ0AAGCGVdU9rbWFtba72OF5n2utPZzkm5P8s9ba9yZ52noqCAAAsBVcbGh6qKpemuTlSd46lF0+mSoBAADMjosNTd+Z5M8l+eHW2keq6pokPze5agEAAMyGNS9umySttQ8k+VtJUlVPTvKk1tptk6wYAADALLjY2fP+Y1V9cVU9Jcn7kry2qn5sslUDAACYvosdnvclrbU/SHJjkte21v5skq+fXLUAAABmw8WGpsuq6mlJvi2PTQQBAACw7V1saPpHGV2f6UOttfdW1TOTfHBy1QIAAJgNFzsRxL9N8m+X3f9wkm+ZVKUAAABmxcVOBHFVVf27qnqgqn6vqn6xqq6adOUAAACm7WKH5702yV1J9iSZT/LvhzIAAIBt7WJD05Wttde21h4ebq9LcuUE6wUAADATLjY0faKq/mpV7RpufzXJf59kxQAAAGbBxYam78pouvHfTfLxJN+a5DsnVSkAAIBZcVGhqbX231pr39Rau7K19tTW2oGMLnQLAACwrV1sT9NKvm/DagEAADCj1hOaasNqAQAAMKPWE5rahtUCAABgRl3WW1lVn87K4aiSzE2kRgAAADOkG5paa0/arIoAAADMovUMzwMAANj2hCYAAIAOoQkAAKBDaAIAAOgQmgAAADqEJgAAgA6hCQAAoENoAgAA6BCaAAAAOoQmAACADqEJAACgQ2gCAADoEJoAAAA6hCYAAIAOoQkAAKBDaAIAAOgQmgAAADqEJgAAgI7Lpl0BLs2R42dy+OjJnD23mD2753Jw/94c2Dc/7WoBAMC2JTRtIUeOn8mhO09k8aFHkiRnzi3m0J0nkkRwAgCACTE8bws5fPTko4FpyeJDj+Tw0ZNTqhEAAGx/QtMWcvbc4iWVAwAA6yc0bSF7ds9dUjkAALB+QtMWcnD/3sxdvuu8srnLd+Xg/r1TqhEAAGx/JoLYQpYmezB7HgAAbB6haYs5sG9eSAIAgE1keB4AAECH0AQAANAhNAEAAHRMLDRV1e1V9UBV3bes7Ieq6v1VdW9V/UpV7RnKq6p+oqpODeufs+wxL6+qDw63l0+qvgAAACuZZE/T65LccEHZ4dbaV7bWnp3krUl+YCh/UZJrh9vNSX46SarqKUleleSrkzw3yauq6skTrDMAAMB5JhaaWmvvTPLJC8r+YNndL0rShuWXJHl9G3l3kt1V9bQk+5O8vbX2ydba7yd5ez4/iAEAAEzMpk85XlU/nORlST6V5OuG4vkkH1u22emhbLXylZ735ox6qfKMZzxjYysNAADsWJs+EURr7ftba09P8vNJXjkU10qbdspXet7XtNYWWmsLV1555cZUFgAA2PGmOXveLyT5lmH5dJKnL1t3VZKznXIAAIBNsamhqaquXXb3m5L89rB8V5KXDbPoPS/Jp1prH09yNMkLq+rJwwQQLxzKAAAANsXEzmmqqjuSPD/JFVV1OqNZ8F5cVXuTfC7Jf03yPcPmv5TkxUlOJfmjJN+ZJK21T1bVDyV577DdP2qtnTe5BAAAwCRVayueIrSlLSwstGPHjk27GgAAwAyrqntaawtrbTfNc5oAAABmntAEAADQITQBAAB0CE0AAAAdQhMAAECH0AQAANAhNAEAAHQITQAAAB1CEwAAQIfQBAAA0CE0AQAAdAhNAAAAHUITAABAh9AEAADQITQBAAB0CE0AAAAdQhMAAECH0AQAANBx2bQrwMY6cvxMDh89mbPnFrNn91wO7t+bA/vmp10tAADYsoSmbeTI8TM5dOeJLD70SJLkzLnFHLrzRJIITgAAMCbD87aRw0dPPhqYliw+9EgOHz05pRoBAMDWJzRtI2fPLV5SOQAAsDahaRvZs3vuksoBAIC1CU3byMH9ezN3+a7zyuYu35WD+/dOqUYAALD1mQhiG1ma7MHseQAAsHGEpm3mwL55IQkAADaQ4XkAAAAdQhMAAECH0AQAANAhNAEAAHQITQAAAB1CEwAAQIfQBAAA0CE0AQAAdAhNAAAAHUITAABAh9AEAADQcdm0K8DmOXL8TA4fPZmz5xazZ/dcDu7fmwP75qddLQAAmGlC0w5x5PiZHLrzRBYfeiRJcubcYg7deSJJBCcAAOgwPG+HOHz05KOBacniQ4/k8NGTU6oRAABsDULTDnH23OIllQMAACNC0w6xZ/fcJZUDAAAjQtMOcXD/3sxdvuu8srnLd+Xg/r1TqhEAAGwNJoLYIZYmezB7HgAAXBqhaQc5sG9eSAIAgEtkeB4AAECH0AQAANAhNAEAAHQITQAAAB1CEwAAQIfQBAAA0CE0AQAAdAhNAAAAHUITAABAh9AEAADQITQBAAB0CE0AAAAdQhMAAECH0AQAANAhNAEAAHQITQAAAB1CEwAAQIfQBAAA0CE0AQAAdEwsNFXV7VX1QFXdt6zscFX9dlW9v6r+XVXtXrbuUFWdqqqTVbV/WfkNQ9mpqrplUvXd6Y4cP5Prb7s719zytlx/2905cvzMtKsEAAAzYZI9Ta9LcsMFZW9P8hWtta9M8jtJDiVJVT0ryU1Jvnx4zE9V1a6q2pXk1UlelORZSV46bMsGOnL8TA7deSJnzi2mJTlzbjGH7jwhOAEAQCYYmlpr70zyyQvKfqW19vBw991JrhqWX5LkDa21z7TWPpLkVJLnDrdTrbUPt9Y+m+QNw7ZsoMNHT2bxoUfOK1t86JEcPnpySjUCAIDZMc1zmr4ryS8Py/NJPrZs3emhbLVyNtDZc4uXVA4AADvJVEJTVX1/koeT/PxS0QqbtU75Ss95c1Udq6pjDz744MZUdIfYs3vuksoBAGAn2fTQVFUvT/KNSb6jtbYUgE4nefqyza5KcrZT/nlaa69prS201hauvPLKja/4NnZw/97MXb7rvLK5y3fl4P69U6oRAADMjk0NTVV1Q5J/kOSbWmt/tGzVXUluqqrHV9U1Sa5N8p4k701ybVVdU1WPy2iyiLs2s847wYF987n1xusyv3sulWR+91xuvfG6HNhnJCQAAFw2qSeuqjuSPD/JFVV1OsmrMpot7/FJ3l5VSfLu1tr3tNbur6o3JflARsP2XtFae2R4nlcmOZpkV5LbW2v3T6rOO9mBffNCEgAArKAeGyG3fSwsLLRjx45NuxoAAMAMq6p7WmsLa203zdnzAAAAZt7EhuexfRw5fiaHj57M2XOL2bN7Lgf37zWUDwCAHUNoouvI8TM5dOeJRy9+e+bcYg7deSJJBCcAAHYEw/PoOnz05KOBacniQ4/k8NGTU6oRAABsLqGJrrPnFi+pHAAAthuhia49u+cuqRwAALYboYmug/v3Zu7yXeeVzV2+Kwf3751SjQAAYHOZCIKupckezJ4HAMBOJTSxpgP75oUkAAB2LMPzAAAAOoQmAACADqEJAACgQ2gCAADoEJoAAAA6zJ7HRB05fsZ05QAAbGlCExNz5PiZHLrzRBYfeiRJcubcYg7deSJJBCcAALYMw/OYmMNHTz4amJYsPvRIDh89OaUaAQDApROamJiz5xYvqRwAAGaR4XmsS++cpT2753JmhYC0Z/fcZlcTAADGpqeJsS2ds3Tm3GJaHjtn6cjxM0mSg/v3Zu7yXec9Zu7yXTm4f+8UagsAAOMRmhjbWucsHdg3n1tvvC7zu+dSSeZ3z+XWG68zCQQAAFuK4XmM7WLOWTqwb15IAgBgSxOaGNt6z1lyDScAALYCw/MY23rOWVrrfCgAAJgVQhNjW885S67hBADAVmF4Husy7jlLruEEAMBWoaeJqVjtvCfXcAIAYNYITUyFazgBALBVGJ7HVCwN6TN7HgAAs05oYmpcwwkAgK3A8DwAAIAOoQkAAKBDaAIAAOgQmgAAADqEJgAAgA6hCQAAoENoAgAA6BCaAAAAOoQmAACADqEJAACgQ2gCAADouGzaFYCVHDl+JoePnszZc4vZs3suB/fvzYF989OuFgAAO5DQxMw5cvxMDt15IosPPZIkOXNuMYfuPJEkghMAAJvO8DxmzuGjJx8NTEsWH3okh4+enFKNAADYyfQ0MXPOnlvslhu6BwDAZtLTxMzZs3tu1fKloXtnzi2m5bGhe0eOn9ncSgIAsGMITcycg/v3Zu7yXeeVzV2+Kwf37zV0DwCATSc0MXMO7JvPrTdel/ndc6kk87vncuuN1+XAvvk1h+4BAMBGc04TM+nAvvkVz1Pas3suZ1YISKsN6QMAgPXS08SW0hu6l4wmibj+trtzzS1vy/W33e1cJwAA1k1PE1vKUu/TSrPnub4TAACTIDSx5aw2dK83SYTQBADAuAzPY9swSQQAAJMgNLFt9K7vBAAA4xKa2DZMEgEAwCQ4p4ltwyQRAABMgtDEtmKSCAAANprheewIJokAAGBcQhM7gkkiAAAYl9DEjrDWJBEAALAa5zSxI/QmibgYR46fGfuxAABsbUITO8Zqk0Ssxcx7AAA7m9AEa1hr5j29UAAA25vQBIPVwk9v5j29UAAA29/EJoKoqtur6oGqum9Z2V+uqvur6nNVtXDB9oeq6lRVnayq/cvKbxjKTlXVLZOqLzvbUvg5c24xLY+FnyPHz3Rn3uv1QgEAsD1Mcva81yW54YKy+5LcmOSdywur6llJbkry5cNjfqqqdlXVriSvTvKiJM9K8tJhW9hQvfDTm3nP9Z8AALa/iYWm1to7k3zygrLfaq2t9BP8S5K8obX2mdbaR5KcSvLc4Xaqtfbh1tpnk7xh2BY2VC/8HNg3n1tvvC7zu+dSSeZ3z+XWG6/LgX3zrv8EALADzMo5TfNJ3r3s/umhLEk+dkH5V29Wpdg59uyey5kVgtNS+Flt5r2D+/eed05T4vpPAADbzaxc3LZWKGud8s9/gqqbq+pYVR178MEHN7RybH/jXvy21wsFAMD2MCs9TaeTPH3Z/auSnB2WVys/T2vtNUlekyQLCwsrBitYzXoufjvu9Z8AANgaZiU03ZXkF6rqx5LsSXJtkvdk1NN0bVVdk+RMRpNF/JWp1ZJtbbPDT+/6Tq79BAAwOyYWmqrqjiTPT3JFVZ1O8qqMJob450muTPK2qrq3tba/tXZ/Vb0pyQeSPJzkFa21R4bneWWSo0l2Jbm9tXb/pOoMG2218NO7vlMS134CAJgh1dr2G8m2sLDQjh07Nu1qsMNdGIyS0XlSt954XQ4fPbnixBPzw8QTq6171y0vmFyFAQB2mKq6p7W2sNZ2szI8D7ad3rWfxrkVnshqAAAWxklEQVS+k2s/AQBMx6zMngfbTi8Y9a7v5NpPAACzRWiCCemFn94U5+NOfw4AwGQYngcT0rvw7cVMcd5bZ3Y9AIDNYyIImKBJhJveBBOC09Yi/ALAdJkIAmbAJK791JtgYhYPuAWDlfWmndc+ADBbhCbYYtaaeW+WLpo7i8FgVkLcVgu/ALCTCU2wxezZPbfidZz27J6bykVzeyFk1oLBLIW4caad345mJcQy4vMAWJnQBFtMb4KJXkhZWl5p3YF982MdLK0VQtbTKzYJsxTieuF3p5ilEIvPA9bLjw7bmynHYYs5sG8+t954XeZ3z6WSzO+ee3QSiF5I6a1bOlg6c24xLY8dLB05fibJ6Ivg+tvuzjW3vC3X33b3o+VrhbTetOtrveYkzFLvziSnll/t85o1a+0/bC6fB4xvGt9pbC49TbAFrTbBxFq9F6utW+tgabVfn9cKIeP2il1MD9c4v+bNUu/OxUw7P46t1FswSyEWnwesxyyNZGAy9DTBNjLuRXN7B0u9L4JeT1Iyfq9Yz3p+zZu1Cwcf2Defd93ygnzktr+Yd93ygg35Yt1KvQVr7T9sLp8HjM+PDtuf0ATbSC+k9Nb1DpZ6XwQXE0JWCwbjHqCtJxT02mC72Epf3LMWYnc6nweMz48O25/hebDN9K4Ntdq6tYbRrTakbT1DzHqvmaw+BG+9oWAS186aJbM0BHEtkxyi6GTsSzepzwN2grW+09j6hCZgzYOl3hfBuCGk95q983LWCgU7/YB5Wl/c414fbKND7FY6p2sWbfcfFWBS/Oiw/VVrbdp12HALCwvt2LFj064GbBubHUSuv+3uFYPR/PDaK4WCW2+8LsnKAe9ih+CN+z5nLahN+yLGycZ9Jpeqt++865YXbPjrbUWztr9uJdoOtp+quqe1trDWdnqagDVt9q/PvSF4vV/zrr/t7nXNyNfroVjtYGkWezZ6n9ckDvrWc32wjbaVzumapK20v24V2o712i6he7u8j0slNAEzZ60heKuFgvUcMI877fpa08yu58tlo7+YJnXQN067TyrEbKVzuial9zmbFnl82m5kpx4wr9d2Cd3b5X2Mw+x5wMwZdxav9cxeNO606+u5aHDPuBcc7pnUdOS9dt/sGaW22wxwG/05b6eeuM2+iPN2artxuYDr+LbS5SB6tsv7GIfQBMyccacGX88B87jTrvcet54vl95jxz1wWeugb9yD0HGvD7aWceqznaaVn8TnvF2mRZ7Gwft2abv12MkHzOu1XUL3dnkf4zA8D5hJ45xHNakp0HvTrvce971vvHfF17qYL5dxe75677U3dG3cc7qW1if9dr/Uz2Q9Q0C2ywxwk/ict8u0yNMYKrdd2m49ZvGAeasMF9wuQ4e3y/sYh9AEbCuTmAI9WX3a9d7jemFrLb0vpnEPXNYKhuOc03UxU4eP85lM8lyxrWISn/N2mRZ5Ggfv26Xt1mMaB8xrXc5gq5xfs11C93Z5H+MQmgAGqx3cr3WwNM5Fg9cybs/XWu9vtffR6xWbxq/6F3Ou2LgHSuNeU2pcaz3nauvHvSbZuPvrVjKtX7u3Q9utx2YfMK/1f30rTc6xXUL3dnkf43CdJoAJmsTseb3rIo37xdW7vtHZ4byRC1WSj9z2F8d6vfXUJ8nY12JazzWlxglba31W49Znrbpud5P4P8DF2cxe3rWuu3bNLW8b+2/TdrkuH+vnOk0AM2A9v0yP2/M1jkn0bK3HpM4VG/eaUsnqQxR769b6Jby3fikAbvQ1yWbNOAehO/nX7uWmcQC/mb1taw3DHLfHcdze6q00HHAtwt+lE5oAtqCNPnAZ95yuSZnUuWLjXlNq3LC11uuttX4S1yRbj40e2rjeCUi2ykHepIZ9bqUD+HHaYK1QNO5wwXGH9W2l4YA9W23fmRVCEwBJNrdnaz31Wc95FWsdhG3k5BtLbdV7vXF/KZ/WCfnj9Lb1ws96JyDZCiZ1Dt6kDuBnKeCt9X993L9N4/7oMIuzB45ju4S/zSY0AbCmWfpVfz0hbq2DsHGHKI47xfe4AXAaM1hNYmjjJKbWXzJur9hGh4b1vI9e2JjEAfykeiDGbYOL+b8+zt+mrfRjxSRsl/C32YQmALacSU0t31s3Tti6mJns1qrPuO9jo01iaOMkptZPxu8V6627mICz0udxMe9jnN6kSRzAT6oHYj2f5SR+sNlKP1asx7gzc7IyoQmAHaV3ELaeIYrjnnuzngC4mb1/kxja+OPf/uyJTECynl6xcUJDL6RdzNTx4/Qm9dpu6XkvtTdtvT0QW+UgfRZ/rNjM8wUnGf628wQTQhMAXIRxwtZ2MomhjZOagGTcXrFx1iX9kLZWu43bm9Rru3F72tYTbqZ1kD6uWfqxYj3nC65m3Jk5J/U+tsPfR6EJAFjTpIY2TmICknF7xdZat5peSFvrfaynN2m1thu3p2094WY9B+mT6p3YKtdiGvfz6tVp3Jk512O7TzAhNAEAF2VSQxvHeb2ecXvF1lq3mrVCWu99jNub1DNuT9t6PqtxD9In1Tuxla7FtNE9o8n6J60YJzhu9wkmhCYAYKI2e/jienrF1lq3kvX00FzMtNobPTvcuAFvPa+5mkn1TmylazGt5/NaLdysZ58cNzhezPl7W/l8J6EJANh2xj0HbZzQsN7etHEfu5r19LRN6jVXM6neia10LaZxP6+LCTfj7FfjBsfe+9gO5zsJTQAA67Se3rSN7olbb0/bpF5zJZOaWW8rXYtp3M/r+tvu7oabcfercYNj732sVdetQGgCANhmpjHb4zjPO6mZ9bbatZjG+bwm1Su2nuC42XXdTF8w7QoAALAzHdg3n1tvvC7zu+dSSeZ3z+XWG6/bkJ6vcZ53UvWZhNVCzHp7xQ7u35u5y3edV7be4Dipum6maq1Nuw4bbmFhoR07dmza1QAAgIm48DyhZBRuNiLkbfSkDZOs63pV1T2ttYW1tjM8DwAAtphJTCKy/Lk3+zy7WaenCQAA2JEutqfJOU0AAAAdQhMAAECH0AQAANAhNAEAAHQITQAAAB1CEwAAQIfQBAAA0CE0AQAAdAhNAAAAHUITAABAh9AEAADQITQBAAB0CE0AAAAdQhMAAECH0AQAANAhNAEAAHQITQAAAB1CEwAAQIfQBAAA0CE0AQAAdFRrbdp12HBV9WCS/7rJL3tFkk9s8mvuNNp4c2jnzaGdJ08bbw7tvDm08+Rp480xa+38J1trV6610bYMTdNQVcdaawvTrsd2po03h3beHNp58rTx5tDOm0M7T5423hxbtZ0NzwMAAOgQmgAAADqEpo3zmmlXYAfQxptDO28O7Tx52nhzaOfNoZ0nTxtvji3Zzs5pAgAA6NDTBAAA0CE0rVNV3VBVJ6vqVFXdMu36bEVV9dGqOlFV91bVsaHsKVX19qr64PDvk4fyqqqfGNr7/VX1nGXP8/Jh+w9W1cun9X5mRVXdXlUPVNV9y8o2rF2r6s8On9up4bG1ue9w+lZp4x+sqjPD/nxvVb142bpDQ3udrKr9y8pX/DtSVddU1W8Mbf/Gqnrc5r272VFVT6+qd1TVb1XV/VX1t4dy+/MG6bSx/XkDVdUTquo9VfW+oZ3/4VC+YttU1eOH+6eG9Vcve65Lav+dpNPOr6uqjyzbn589lPubMaaq2lVVx6vqrcP97bsvt9bcxrwl2ZXkQ0memeRxSd6X5FnTrtdWuyX5aJIrLij7J0luGZZvSfIjw/KLk/xykkryvCS/MZQ/JcmHh3+fPCw/edrvbcrt+rVJnpPkvkm0a5L3JPlzw2N+OcmLpv2eZ6SNfzDJ31th22cNfyMen+Sa4W/Hrt7fkSRvSnLTsPwzSf76tN/zlNr5aUmeMyw/KcnvDO1pf558G9ufN7adK8kTh+XLk/zGsI+u2DZJ/kaSnxmWb0ryxnHbfyfdOu38uiTfusL2/maM39bfl+QXkrx1uL9t92U9Tevz3CSnWmsfbq19NskbkrxkynXaLl6S5F8Py/86yYFl5a9vI+9OsruqnpZkf5K3t9Y+2Vr7/SRvT3LDZld6lrTW3pnkkxcUb0i7Duu+uLX2X9ror97rlz3XjrFKG6/mJUne0Fr7TGvtI0lOZfQ3ZMW/I8Ovli9I8ubh8cs/rx2ltfbx1tpvDsufTvJbSeZjf94wnTZejf15DMM++YfD3cuHW8vqbbN8H39zkr8wtOUltf+E39bM6bTzavzNGENVXZXkLyb5l8P93v/zLb8vC03rM5/kY8vun07/S4aVtSS/UlX3VNXNQ9kfb619PBl9mSd56lC+Wpv7LC7ORrXr/LB8YTkjrxyGeNxew5CxXHob/7Ek51prD19QvqMNQzr2ZfTLsf15Ai5o48T+vKGG4Uz3Jnkgo4PwD2X1tnm0PYf1n8qoLX0XruHCdm6tLe3PPzzszz9eVY8fyvzNGM8/S/L3k3xuuN/7f77l92WhaX1WGr9qOsJLd31r7TlJXpTkFVX1tZ1tV2tzn8X6XGq7au/V/XSSL03y7CQfT/KjQ7k2XqeqemKSX0zyd1prf9DbdIUybX0RVmhj+/MGa6090lp7dpKrMvo1/X9aabPhX+08pgvbuaq+IsmhJH86yVdlNOTuHwyba+dLVFXfmOSB1to9y4tX2HTb7MtC0/qcTvL0ZfevSnJ2SnXZslprZ4d/H0jy7zL6Evm9ofs7w78PDJuv1uY+i4uzUe16eli+sHzHa6393vBl/bkkP5vR/pxceht/IqMhIpddUL4jVdXlGR3M/3xr7c6h2P68gVZqY/vz5LTWziX5jxmdQ7Na2zzansP6L8loSLDvwou0rJ1vGIahttbaZ5K8NuPvz/5mJNcn+aaq+mhGQ+dekFHP07bdl4Wm9XlvkmuHmUIel9GJbXdNuU5bSlV9UVU9aWk5yQuT3JdROy7NUvPyJG8Zlu9K8rJhppvnJfnUMCznaJIXVtWTh+EjLxzKON+GtOuw7tNV9bxhTPLLlj3XjrZ0ED/45oz252TUxjcNMwhdk+TajE4kXvHvyDBO/h1JvnV4/PLPa0cZ9rF/leS3Wms/tmyV/XmDrNbG9ueNVVVXVtXuYXkuyddndP7Yam2zfB//1iR3D215Se0/+Xc2W1Zp599e9iNLZXSuzfL92d+MS9BaO9Rau6q1dnVG+9ndrbXvyHbel9sMzLyxlW8ZzbjyOxmNSf7+addnq90ymhXlfcPt/qU2zGic668l+eDw71OG8kry6qG9TyRZWPZc35XRCYSnknzntN/btG9J7shoOM1DGf1i890b2a5JFjL6wvlQkp/McLHsnXRbpY3/zdCG78/oD/zTlm3//UN7ncyymZZW+zsy/P94z9D2/zbJ46f9nqfUzv9LRsMy3p/k3uH2YvvzprSx/Xlj2/krkxwf2vO+JD/Qa5skTxjunxrWP3Pc9t9Jt0473z3sz/cl+bk8NsOevxnra+/n57HZ87btvlxDpQAAAFiB4XkAAAAdQhMAAECH0AQAANAhNAEAAHQITQAAAB1CE8AMqao/VlX3Drffraozy+4/7iKf47VVtXeNbV5RVd+xMbVe8flvrKo/PannH17jC6rqHVX1xKq6rKoeWdZW91bVwQ18rT9VVfdu1PON8foTb8/hdf7vqvr2C8peVlUnqur9VfWuqrpuKH9CVf16Ve2adL0Apu2ytTcBYLO01v57kmcnSVX9YJI/bK390+XbDBdTrNba51Z5ju+8iNd59fpr23Vjks8l+e0JvsZfSnKstfaHwxXmP91ae/YEX2+aNqM9k+QbMrpezXIfSvI1rbVzVfWXkvxMkutba/9fVb0zowtVvnHC9QKYKj1NAFvA0NNxX1X9TJLfTPK0qnpNVR2rqvur6geWbfufq+rZQ+/Luaq6rareV1X/paqeOmzzj6vq7yzb/raqek9Vnayq/3ko/6Kq+sXhsXcMr/V5oaSqDlfVB4aeiB+pqq/J6KKEPz70+FxdVddW1dGquqeq3llVXzY89ueq6qer6j9V1e9U1YuG8uuq6r3D499fVc9coVm+I49dbb7XdqeXvb/fWHqu4Urz7xie/+1VddVQ/ieq6i1D+fuq6quHp7qsqv7V0N6/XFVPGLb/3uH9v6+qfu6iPtB+fafSnlW1O0laa59cXt5ae1dr7dxw991Jrlq2+khGnwPAtqanCWDreFZGV6T/niSpqltaa58celneUVVvbq194ILHfEmSX2+t3VJVP5bR1e1vW+G5q7X23Kr6piQ/kOSGJH8zye+21r6lqv5MRmHt/AdV/fGMDui/vLXWqmr30CPxS0ne3Fo7Mmz3jiT/e2vtQ1V1fZKfTPLC4WmenuTPJ7k2ya9W1Z9K8jeS/NPW2hur6vFJaoU6X5/kf1t2/0l1/hC6f9xae/Ow/PvD+/uuJD+W5ECSn0ryL1trP19VNyf5Zxn1mrw6ydtbaz85tO0XJnlqkr1JXtpaO1FVdw7P8YYkfz/Jn2ytfXYpeFzQRs9K8gsr1D8Z9eB8ekba84VJfnWVei757iS/vOz++5I8b43HAGx5QhPA1vGh1tp7l91/aVV9d0Z/y/dkFKouDE2LrbWlg9x7knzNKs9957Jtrh6W/5ckP5IkrbX3VdX9KzzukxkNG/vZqnpbkrdeuMEQJJ6X5BerHj1WX/7986ZhqOHJqvpYRgf7/2+S/6uq/mSSO1trp1Z47Se11v5o2f3e8Lw7hn9/Po+Fxq9O8o3D8uuT/NCw/PwkNyVJa+3hJH8w9NCdaq2dGLZZ3k73J/m5qnpLRj0v5xmC7MUOG5xme96Q5KdXq1hVfX2S/zWj/WLpvT1cVa2q5lprixf5HgG2HMPzALaO/7G0UFXXJvnbSV7QWvvKJP8hyRNWeMxnly0/ktV/LPvMCtus1BtxntbaQ0kWMgoL35LkbStsVkk+0Vp79rLbVyx/ms9/2vZvknzzUK+3V9XXrvC8K57TtVpVL2Hb1bb/zLLl5e20P6PzfJ6b5FhdMDFCVT2rzp+gYvntSee96HTb889mFAY//wVHwzL/RZKXtNZ+/4LVj8v5bQOw7QhNAFvTFyf5dEa9IE/L6MB9o/3nJN+WjM6Jyagn6zzDQf8Xt9bemuR7k+wbVn06yZOSZDjI/nhVffPwmC8Yhvst+cs18mUZDS37YFU9s7V2qrX2/2QUHL5yhfqdqqqrL/K9LM0I99Ik7xqW3730/pL81STvHJbfkWRpCOSuqvri1Z50CEhXtdbuTnIwyZUZDed7VGvtAxcEnOW3T1/wfFNpz+HxJ1aaXGRo4zcn+SsX9lANwwnPrDYpCcB2ITQBbE2/mdFQvPuS/GweCwIb6Z8nma+q9yf5u8NrfeqCbb4kyduq6n1J7k7yfUP5HUn+z6WJCzIa7vY9w3b357FhcUlyKqPA8u+T3Nxa+2ySvzJMuHBvkmcmWWmChbdlNJRuyZMu6MX54WXrvrCq3pPkrw/vJUlemeTm4f19e0YhZal8f1WdSHIsSW+q78uS/MLwHL+Z5EcuDEKXaFrt+aKMeitX8oNJnpLkXwyv/xvL1n1dVu4NA9hWqrVLHbEAwE4wTIJw2TC19LVJfiXJtcN5Phv1Gj+XZRMcXOJjr8poIocb1tjudJKvWDYD3LY1bntW1d1Jvr219uAlPu4tSf7uKudIAWwbJoIAYDVPTPJrQ3iqJH9tIwPTerXWTlfV66rqia21P5x2fbay1toLLvUxwyx8bxaYgJ1ATxMAAECHc5oAAAA6hCYAAIAOoQkAAPj/268DAQAAAABB/tYbTFAWMaQJAABgSBMAAMCQJgAAgBHJogbBJVlEaQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x286067e3748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt  \n",
    "%matplotlib inline\n",
    "\n",
    "# manually set the parameters of the figure to and appropriate size\n",
    "plt.rcParams['figure.figsize'] = [14, 10]\n",
    "\n",
    "loss_values = [ev['loss'] for ev in evaluations]  \n",
    "training_steps = [ev['global_step'] for ev in evaluations]\n",
    "\n",
    "plt.scatter(x=training_steps, y=loss_values)  \n",
    "plt.xlabel('Training steps (Epochs = steps / 2)')  \n",
    "plt.ylabel('Loss (SSE)')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
